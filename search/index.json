[{"content":"\n科研日记 用来记录我远程实习的日子\n2025.07.16 成为赵老师的本科实习生，暑假跟着师兄做了一个横向\n家里网好差（本来服务器就慢），还是要在学校多用功 暑假一共6周，还有各种事情，加上休息吃饭探亲balabala也做不了太多事情。确定了方向，看了一些知乎上的论文解读（后面发现如果要通透还是要看原文）。\n2025.09.16 近期在搞论文复现的实验，跟上课题组的进度\n今天在修改run_dapo.sh脚本的时候发现了几个常见的问题\n.sh的格式十分严格 Parquet文件格式 Parquet文件格式讲解👈\nvibe coding脚本是无比正确的。\n不知不觉已经两个月了，但对我而言收获是颇多的。\n选择一个好组是十分重要的！软院TIC，高瓴AI BOX让我深刻感受到了好的氛围，成套的培养体系！ 希望自己可以平衡好课内＋科研，还有生活等等其他方面 晚上睡前简单看了一下verl官方文档里面Config Explanation的Data部分\n梯度下降的三种常见形式 1.Batch Gradient Descent（批量梯度下降） 2.Stochastic Gradient Descent (SGD，随机梯度下降) 3.Mini-batch Gradient Descent（小批量梯度下降） 几个epoch就是过几次数据集，实践中把 “batch” 这个词用得比较宽：在框架/代码里 batch_size 常指 mini-batch 的大小，所以容易混淆 “batch gradient descent” 与 “mini-batch”。\nprompt_key 这个不是学术上固定的术语，而是很多框架（比如 HuggingFace、VERL、LangChain 等）里常见的实现细节。\n在 字典 / JSON / 配置文件 里，用来标记某个 prompt 的 键名（key）。 这样做可以在代码里快速查找/复用不同的 prompt 模板。 1 2 3 4 5 prompts = { \u0026#34;translation\u0026#34;: \u0026#34;Translate the following English text into Chinese: {text}\u0026#34;, \u0026#34;summarization\u0026#34;: \u0026#34;Summarize the following paragraph: {text}\u0026#34;, \u0026#34;qa\u0026#34;: \u0026#34;Answer the question based on the context: {context}\\nQuestion: {question}\u0026#34; } 这里 \u0026ldquo;translation\u0026rdquo;, \u0026ldquo;summarization\u0026rdquo;, \u0026ldquo;qa\u0026rdquo; 就是 prompt_key， 而它们对应的 value 就是具体的 prompt 模板。\nPrompt = 给模型的输入提示，引导它完成任务。\nPrompt_key = 在程序里标记或索引 prompt 模板的“名字/键”，方便管理和调用。\nRM（Reward Model，奖励模型）：在 RLHF 里给生成结果打分的模型。\n如果使用基于模型的 RM，并且策略和 RM 的聊天模板不同，则需要设置data.return_raw_input_ids=True data.return_full_prompt=True 用户输入：你好，介绍一下强化学习 返回：[INST] 你好，介绍一下强化学习 [/INST] data.return_raw_chat=True 用户输入：你好，介绍一下强化学习 返回的就是:你好，介绍一下强化学习\n2025.09.17 早晨起来去工位继续看verl\nactor_rollout_ref.hybrid_engine：是否是混合引擎，目前只支持混合引擎.\nDropout 是一种 正则化方法，用来防止神经网络过拟合。在训练时，随机“丢弃”一部分神经元（让它们暂时不参与计算和更新）。推理时,不再丢弃任何神经元，只是使用完整的输出。\nactor_rollout_ref.model.use_remove_padding一般都选true移除\u0026lt;PAD\u0026gt;来加速推理，但是多模态或者大工程里仍有人使用false\nTemperature （温度）。T = 1 → 正常分布。T \u0026gt; 1 → 分布更平滑，增加随机性，容易生成多样化甚至跑偏的内容。T \u0026lt; 1 → 分布更尖锐，模型更确定（更倾向选概率最高的 token，输出保守）。\nTop-k：从 softmax 排序后的前 k 个 token 中随机抽样。\nTop-p：动态选择前 累计概率 ≥ p 的最小 token 集合，从里面采样。\nActor:负责 更新参数\nRef (Reference Model):负责 对比/约束。它是冻结的（不更新），通常是最初的预训练模型。\nRollout:负责 产生输出（推理采样）\nEOS = End Of Sequence（序列结束标记）。在 tokenizer 里，EOS 往往是个特殊的 \u0026lt;/s\u0026gt; 或 \u0026lt;eos\u0026gt; 符号。ignore_eos=True 在训练中一般少用，除非你需要 生成固定长度序列，或者想收集超过 EOS 的 rollouts 数据。\n2025.09.19 一个深度学习训练任务中，nodes 指的是计算机，而 gpus-per-node 指的是每台计算机上安装的 GPU 数量。\n可以把 nodes 理解为一台台服务器，每台服务器里可以插上多张显卡（GPU）。\nnnodes: 1：你正在使用一台计算机来运行任务。\nn_gpus_per_node: 8：这台计算机上插了 8 张 GPU。\n所以，这个配置的意思是，你用一台装有 8 张 GPU 的服务器来运行你的任务。\nverl官方文档看完了，嗯。。还是要去看仓库\n都在赶iclr导致服务器又变得卡卡的\n实验复现遇到了问题导致一直是卡住的状态\n神器：\npkill -9 -u $USER -f ray\n2025.09.20 ray官方仓库，试图解决Ray实例后ray.init()挂起/失败问题\nimport ray ray.init() 2025-09-20 11:44:47,741 INFO worker.py:1538 \u0026ndash; Started a local Ray instance.\n有时候会卡住\npython import ray ray.init() 2025-09-20 11:44:47,741 INFO worker.py:1538 \u0026ndash; Started a local Ray instance.\n有时候会失败\n[2025-09-20 11:50:22,050 E 31652 31652] core_worker.cc:179: Failed to register worker 01000000ffffffffffffffffffffffffffffffffffffffffffffffff to Raylet. IOError: [RayletClient] Unable to register worker with raylet. No such file or directory\nVersions/Dependencies Python 3.10 Ray grpcio OS:\nReproduction script import ray ray.init()\nIssue Severity High:It blocks me from completing my task.\n可能的原因:1.workers实际上没有启动 2.系统中一个进程可以创建多少个线程？（可以通过cat /proc/sys/kernel/threads-max查看）\n可能的方法:1.在import ray后添加 ray.init(num_cpus=56, num_gpus=2) 2.可以看一下/tmp/ray/session_latest/raylet.out,如果在/tmp/ray/session_latest/看到有前缀python-core-worker- 的可以看一下，因为这个能了解工作进程可能发生了什么 3.升级grpcio\n","date":"2025-09-16T10:00:00+08:00","image":"http://localhost:1313/p/ruc-study-framework/RUC_hu_19ceed1f7aef8036.jpg","permalink":"http://localhost:1313/p/ruc-study-framework/","title":"RUC科研之旅"},{"content":"欢迎你能来到我的第一篇文章！\n为什么要写博客？ 写博客对我来说有着特殊的意义：\n对自己 记录笔记：把学到的东西都记下来，以后可以复习 积攒经验：积攒宝贵的经验 记录进步：记录自己的进步 对他人 感谢师父：感谢文聪学长的帮助，永远的师傅！ 传承精神：希望后来者能够更快速地入门 分享内容：希望其他人能够更快地了解我 博客内容规划 我计划我的文章中记录以下内容：\n笔记 (Notes) 可能比较杂，什么都有。但重点是关于强化学习的内容\n理论 (Theory) 一些理论知识\n日记 (Diary) 记录一些自己的日常，探讨人生\n结语 写博客是一个长期的过程，也应该是一个很开心的过程！\n这篇文章写于 2025年9月15日，是我博客的第一篇文章。希望它能成为一个美好的开始。\n","date":"2025-09-15T00:00:00Z","image":"http://localhost:1313/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/first-blog-cover_hu_19f8cf5e7cdc0c7d.jpg","permalink":"http://localhost:1313/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/","title":"第一篇文章"}]