[{"content":"\nPass@k论文复现 Pass@k Training for Adptively Balancing Eplortion and Exploitation of LRMs arxiv文章👈\ngithub仓库👈\nDatasets👈\nVersions/Dependencies Python 3.10.18\nRay 2.49.1\ngrpcio 1.75.0\nUbuntu 24.04.2 LTS\n如何从huggingface上下载数据集和模型 从huggingface上下载文件有2种方式，一种是直接登录后在网页上下载；一种是通过huggingface-cli命令下载。\n本文介绍的是第二种下载方式。\n安装 对于huggingface-cli命令的下载直接通过pip命令安装即可：\npip install -U huggingface_hub[hub_transfer]\n对于国内用户还可以通过设置镜像网站的方式加速下载：\n#linux export HF_ENDPOINT=https://hf-mirror.com\n#windows\nset HF_ENDPOINT=https://hf-mirror.com\n使用命令行下载\n模型 huggingface-cli download \u0026ndash;resume-download [1] \u0026ndash;local-dir [2] \u0026ndash;local-dir-use-symlinks False\n数据集 huggingface-cli download \u0026ndash;repo-type dataset \u0026ndash;resume-download [3] \u0026ndash;local-dir [4] \u0026ndash;local-dir-use-symlinks False \u0026ndash;token hf_***\n格式为：[1]和[3]表示项目的路径，格式为用户名/项目，比如mistralai/Mistral-7B-Instruct-v0.2表示的是mistralai下的7B instruct v0.2权重。[2]和[4]表示的是本地的保存地址。\n需要的注意的是有些仓库需要登录才可以下载，形如–token hf_***为huggingface的token配置。token的生成需要在huggingface个人页面生成.\n","date":"2025-09-21T16:00:00+08:00","image":"http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/ByteDance_hu_b5130faa32e5aa6a.jpg","permalink":"http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/","title":"Pass@k论文复现"},{"content":"Abstract 此文章发布约一周前就已经发现该问题了，但是由于专注看官方文档和仓库进行规范 + 课内事情，一直没有得到解决。\n在发文前一天发现此问题需要重点解决（无法避免），询问了师兄（论文作者）并咨询了相关团队，未果，所以花了两整天才解决这一个bug。\nIssue What happened + What you expected to happen Running the following snippet will hang indefinitely\n1 2 3 \u0026gt;\u0026gt;\u0026gt; import ray \u0026gt;\u0026gt;\u0026gt; ray.init() 2025-09-20 11:44:47,741 INFO worker.py:1538 -- Started a local Ray instance. Sometimes it will fail instead\n1 [2025-09-20 11:50:22,050 E 31652 31652] core_worker.cc:179: Failed to register worker 01000000ffffffffffffffffffffffffffffffffffffffffffffffff to Raylet. IOError: [RayletClient] Unable to register worker with raylet. No such file or directory Versions/Dependencies Python 3.10.18\nRay 2.49.1\ngrpcio 1.75.0\nUbuntu 24.04.2 LTS\nReproduction script 1 2 import ray ray.init() Issue Severity High: It blocks me from completing my task.\n上面全英是因为当时要提issue或者给Ray框架作者发邮件，但是后来解决了，就打算留下来了，这样后来的人可以模仿一下这个写法。\n可能的问题 1.workers实际上并没有启动。（可以看一下/tmp/ray/session_latest/raylet.out,如果在/tmp/ray/session_latest/看到有前缀python-core-worker- 的可以看一下，因为这个能了解工作进程可能发生了什么） 2.系统中进程数/线程数设置错误（可以通过cat /proc/sys/kernel/threads-max查看系统中一个进程可以创建多少个线程） 可能的方法 1.在import ray之后加上ray.init(num_cpus=56, num_gpus=2)。具体参数需要根据服务器进行自定义。 作者根据这个方法对自己进行了适配解决了问题。 具体操作：/yhy/verl/trainer/config/ppo_trainer.yaml配置文件中对num_cpus=0修改成num_cpus=10, num_gpus=1进行定义。 2.升级grpcio,2023年的时候安装grpcio 1.48.1 版本是有用的,相应的venv是 CentOS 7,Python 3.7.11，Ray 2.5.1,grpcio1.48.1。\n但我进行升级的时候，无法解决该问题，并且会导致包之间的冲突。（是一个opencv的包，已经pip install了） 3.添加ulimit -n 65536语句，因为分布式训练一开始可能会开成千上万个进程，默认是4096，所以会导致线程创建失败。 感觉这点也是有用的，但可能不是主要因素？ 4.一定要设置参数,只是用ray.init()就会崩溃。需要手动设置num_cpus。\n这点和1重复了，可以说是大家实验得到的结论？（也许） 近期其他人也遇到过该问题 2024.1.16也有在Ubuntu 20.04上遇到同样的问题 venv: ray == 2.7.1,grpcio == 1.59.2,python == 3.11.5\n2024.4.2有在ubuntu 22.04.3（docker内部）上遇到同样的问题，但是他只是失败，而不是挂起。在docker之外运行良好（他的M1 MacBook上）\n2024.4.14，2024.4.17，2024.7.11等等太多人遇到同样的问题了\n至此，问题的解决方案已经讲述完毕。 回顾解决问题的流程 刚遇到这个问题，我先看了一下是不是自己遇到过的，发现没有就交给了copilot，发现copilot无法解决，给了chatgpt5，同样无法解决，又给了Gemini看看能不能有些新意（其实这步可以忽略），上述方法都不行，问了师兄是否遇到过。\n发现他们都没有遇到过，我只能去Ray官方仓库里面的issue进行查看。感觉现在人们都不怎么用StackOverflow等等论坛了，所以就只能去issue里面找了。\n幸运的是发现了很多人遇到了同样的问题和报错，我就开始追根溯源，发现从17.18年就有人提出了这个问题，当时也有相应的解决办法，但是随着版本更新变得不适用。\n我就开始收集所有对这个问题的理解和解决方案，逐个尝试，很幸运的是我debug成功了！\n因为论文中没有常见的问题的解决方案，如果有的话应该是第一步先去看的。\n这就是我整个解决这个问题的流程，大体上看似乎没有太大问题。但是还是可以优化一下，下次遇到类似比较“偏”的问题可以更快，心态更平和地解决这个问题。\n看到这里了，祝你遇到像我遇到的这样比较“偏门”的问题时，也可以顺利并更快地解决！ ","date":"2025-09-20T10:00:00+08:00","image":"http://localhost:1313/p/ray.init%E5%88%9D%E5%A7%8B%E5%8C%96%E6%8C%82%E8%B5%B7/%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3/Ray_hu_8d061ec42dec3d1e.jpg","permalink":"http://localhost:1313/p/ray.init%E5%88%9D%E5%A7%8B%E5%8C%96%E6%8C%82%E8%B5%B7/%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3/","title":"ray.init()初始化挂起/失败问题的解决"},{"content":"\n科研日记 用来记录我远程实习的日子\n2025.07.16 成为赵老师的本科实习生，暑假跟着师兄做了一个横向\n家里网好差（本来服务器就慢），还是要在学校多用功 暑假一共6周，还有各种事情，加上休息吃饭探亲balabala也做不了太多事情。确定了方向，看了一些知乎上的论文解读（后面发现如果要通透还是要看原文）。\n2025.09.16 近期在搞论文复现的实验，跟上课题组的进度\n今天在修改run_dapo.sh脚本的时候发现了几个常见的问题\n.sh的格式十分严格 Parquet文件格式 Parquet文件格式讲解👈\nvibe coding脚本是无比正确的。\n不知不觉已经两个月了，但对我而言收获是颇多的。\n选择一个好组是十分重要的！软院TIC，高瓴AI BOX让我深刻感受到了好的氛围，成套的培养体系！ 希望自己可以平衡好课内＋科研，还有生活等等其他方面 晚上睡前简单看了一下verl官方文档里面Config Explanation的Data部分\n梯度下降的三种常见形式 1.Batch Gradient Descent（批量梯度下降） 2.Stochastic Gradient Descent (SGD，随机梯度下降) 3.Mini-batch Gradient Descent（小批量梯度下降） 几个epoch就是过几次数据集，实践中把 “batch” 这个词用得比较宽：在框架/代码里 batch_size 常指 mini-batch 的大小，所以容易混淆 “batch gradient descent” 与 “mini-batch”。\nprompt_key 这个不是学术上固定的术语，而是很多框架（比如 HuggingFace、VERL、LangChain 等）里常见的实现细节。\n在 字典 / JSON / 配置文件 里，用来标记某个 prompt 的 键名（key）。 这样做可以在代码里快速查找/复用不同的 prompt 模板。 1 2 3 4 5 prompts = { \u0026#34;translation\u0026#34;: \u0026#34;Translate the following English text into Chinese: {text}\u0026#34;, \u0026#34;summarization\u0026#34;: \u0026#34;Summarize the following paragraph: {text}\u0026#34;, \u0026#34;qa\u0026#34;: \u0026#34;Answer the question based on the context: {context}\\nQuestion: {question}\u0026#34; } 这里 \u0026ldquo;translation\u0026rdquo;, \u0026ldquo;summarization\u0026rdquo;, \u0026ldquo;qa\u0026rdquo; 就是 prompt_key， 而它们对应的 value 就是具体的 prompt 模板。\nPrompt = 给模型的输入提示，引导它完成任务。\nPrompt_key = 在程序里标记或索引 prompt 模板的“名字/键”，方便管理和调用。\nRM（Reward Model，奖励模型）：在 RLHF 里给生成结果打分的模型。\n如果使用基于模型的 RM，并且策略和 RM 的聊天模板不同，则需要设置data.return_raw_input_ids=True data.return_full_prompt=True 用户输入：你好，介绍一下强化学习 返回：[INST] 你好，介绍一下强化学习 [/INST] data.return_raw_chat=True 用户输入：你好，介绍一下强化学习 返回的就是:你好，介绍一下强化学习\n2025.09.17 早晨起来去工位继续看verl\nactor_rollout_ref.hybrid_engine：是否是混合引擎，目前只支持混合引擎.\nDropout 是一种 正则化方法，用来防止神经网络过拟合。在训练时，随机“丢弃”一部分神经元（让它们暂时不参与计算和更新）。推理时,不再丢弃任何神经元，只是使用完整的输出。\nactor_rollout_ref.model.use_remove_padding一般都选true移除\u0026lt;PAD\u0026gt;来加速推理，但是多模态或者大工程里仍有人使用false\nTemperature （温度）。T = 1 → 正常分布。T \u0026gt; 1 → 分布更平滑，增加随机性，容易生成多样化甚至跑偏的内容。T \u0026lt; 1 → 分布更尖锐，模型更确定（更倾向选概率最高的 token，输出保守）。\nTop-k：从 softmax 排序后的前 k 个 token 中随机抽样。\nTop-p：动态选择前 累计概率 ≥ p 的最小 token 集合，从里面采样。\nActor:负责 更新参数\nRef (Reference Model):负责 对比/约束。它是冻结的（不更新），通常是最初的预训练模型。\nRollout:负责 产生输出（推理采样）\nEOS = End Of Sequence（序列结束标记）。在 tokenizer 里，EOS 往往是个特殊的 \u0026lt;/s\u0026gt; 或 \u0026lt;eos\u0026gt; 符号。ignore_eos=True 在训练中一般少用，除非你需要 生成固定长度序列，或者想收集超过 EOS 的 rollouts 数据。\n2025.09.19 一个深度学习训练任务中，nodes 指的是计算机，而 gpus-per-node 指的是每台计算机上安装的 GPU 数量。\n可以把 nodes 理解为一台台服务器，每台服务器里可以插上多张显卡（GPU）。\nnnodes: 1：你正在使用一台计算机来运行任务。\nn_gpus_per_node: 8：这台计算机上插了 8 张 GPU。\n所以，这个配置的意思是，你用一台装有 8 张 GPU 的服务器来运行你的任务。\nverl官方文档看完了，嗯。。还是要去看仓库\n都在赶iclr导致服务器又变得卡卡的\n实验复现遇到了问题导致一直是卡住的状态\n神器：\npkill -9 -u $USER -f ray\n2025.09.20 ray官方仓库，试图解决Ray实例后ray.init()挂起/失败问题\nimport ray ray.init() 2025-09-20 11:44:47,741 INFO worker.py:1538 \u0026ndash; Started a local Ray instance.\n有时候会卡住\npython import ray ray.init() 2025-09-20 11:44:47,741 INFO worker.py:1538 \u0026ndash; Started a local Ray instance.\n有时候会失败\n[2025-09-20 11:50:22,050 E 31652 31652] core_worker.cc:179: Failed to register worker 01000000ffffffffffffffffffffffffffffffffffffffffffffffff to Raylet. IOError: [RayletClient] Unable to register worker with raylet. No such file or directory\nVersions/Dependencies Python 3.10 Ray grpcio OS:\nReproduction script import ray ray.init()\nIssue Severity High:It blocks me from completing my task.\n可能的原因:1.workers实际上没有启动 2.系统中一个进程可以创建多少个线程？（可以通过cat /proc/sys/kernel/threads-max查看）\n可能的方法:1.在import ray后添加 ray.init(num_cpus=56, num_gpus=2) 这个方法很多人似乎有帮助，但不是一个好的解决方案 2.可以看一下/tmp/ray/session_latest/raylet.out,如果在/tmp/ray/session_latest/看到有前缀python-core-worker- 的可以看一下，因为这个能了解工作进程可能发生了什么 3.升级grpcio,2023年的时候安装grpcio 1.48.1 版本是有用的,相应的venv是 CentOS 7,Python 3.7.11，Ray 2.5.1,grpcio1.48.1 4.\n#!/bin/bash ulimit -n 65536 python3 -m verl.trainer.main_ppo \u0026hellip;\n5.一定要设置参数,只是用ray.init()就会崩溃。需要手动设置num_cpus\n其他人： 2024.1.16也有在Ubuntu 20.04上遇到同样的问题 venv: ray == 2.7.1,grpcio == 1.59.2,python == 3.11.5 2024.4.2有在ubuntu 22.04.3（docker内部）上遇到同样的问题，但是他只是失败，而不是挂起。在docker之外运行良好（他的M1 MacBook上）\n2024.4.14，2024.4.17，2024.7.11等等太多人遇到同样的问题了\n15点左右,/yhy/verl/trainer/config/ppo_trainer.yaml配置文件中进行修改\n问题已解决！在import ray后添加 ray.init(num_cpus=56, num_gpus=2) 今天最开心的事情，自己成功看issue，扒仓库源码等等解决了这个问题\n","date":"2025-09-16T10:00:00+08:00","image":"http://localhost:1313/p/ruc-study-framework/RUC_hu_19ceed1f7aef8036.jpg","permalink":"http://localhost:1313/p/ruc-study-framework/","title":"RUC科研之旅"},{"content":"欢迎你能来到我的第一篇文章！\n为什么要写博客？ 写博客对我来说有着特殊的意义：\n对自己 记录笔记：把学到的东西都记下来，以后可以复习 积攒经验：积攒宝贵的经验 记录进步：记录自己的进步 对他人 感谢师父：感谢文聪学长的帮助，永远的师傅！ 传承精神：希望后来者能够更快速地入门 分享内容：希望其他人能够更快地了解我 博客内容规划 我计划我的文章中记录以下内容：\n笔记 (Notes) 可能比较杂，什么都有。但重点是关于强化学习的内容\n理论 (Theory) 一些理论知识\n日记 (Diary) 记录一些自己的日常，探讨人生\n结语 写博客是一个长期的过程，也应该是一个很开心的过程！\n这篇文章写于 2025年9月15日，是我博客的第一篇文章。希望它能成为一个美好的开始。\n","date":"2025-09-15T00:00:00Z","image":"http://localhost:1313/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/first-blog-cover_hu_19f8cf5e7cdc0c7d.jpg","permalink":"http://localhost:1313/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/","title":"第一篇文章"}]