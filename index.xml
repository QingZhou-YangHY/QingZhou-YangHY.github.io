<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Huanyu Yang</title>
        <link>http://localhost:1313/</link>
        <description>Recent content on Huanyu Yang</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>Huanyu Yang</copyright>
        <lastBuildDate>Mon, 26 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Be a good engineer</title>
        <link>http://localhost:1313/p/be-a-good-engineer/</link>
        <pubDate>Mon, 26 Jan 2026 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/be-a-good-engineer/</guid>
        <description>&lt;h2 id=&#34;成为一个好的工程师&#34;&gt;成为一个好的工程师
&lt;/h2&gt;&lt;h3 id=&#34;基本功笔记&#34;&gt;基本功笔记
&lt;/h3&gt;&lt;p&gt;主流并行框架（DDP/DeepSpeed/Megatron）均基于 SPMD（Single Program Multiple Data）架构：所有进程执行相同代码逻辑，通过环境变量差异自主确定行为模式，无需中心调度节点。灵活性不如single-controller模式。&lt;/p&gt;
&lt;p&gt;计算GPU称为Worker，梯度聚合GPU称为Server&lt;/p&gt;
&lt;h4 id=&#34;allreduce&#34;&gt;AllReduce
&lt;/h4&gt;&lt;p&gt;目前最通用的AllReduce方法：Ring-AllReduce。它由百度最先提出，非常有效地解决了数据并行中通讯负载不均的问题，使得DDP得以实现&lt;/p&gt;
&lt;p&gt;Ring-ALLReduce(&amp;ldquo;先富带动后富&amp;quot;思想)则分两大步骤实现该目标：Reduce-Scatter(圆排列转一圈后所有参数都有一个位置已经都更新完成)和All-Gather(把每一部分更新完的参数更新到其他的)&lt;/p&gt;
&lt;p&gt;Ring-AllReduce的方法，因为在之后的ZeRO，Megatron-LM中，它将频繁地出现，是分布式训练系统中重要的算子&lt;/p&gt;
&lt;h4 id=&#34;zerodp&#34;&gt;ZeRO(DP)
&lt;/h4&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/617133971&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：数据并行上篇(DP, DDP与ZeRO)&lt;/a&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/618865052&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：数据并行下篇(DeepSpeed ZeRO，零冗余优化)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ZeRO是模型并行的形式，数据并行的实质&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型并行，是指在forward和backward的过程中，我只需要用自己维护的那块W来计算就行。即同样的输入X，每块GPU上各算模型的一部分，最后通过某些方式聚合结果。
但对ZeRO来说，它做forward和backward的时候，是需要把各GPU上维护的W聚合起来的，即本质上还是用完整的W进行计算。它是不同的输入X，完整的参数W，最终再做聚合。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对activation的存储是灵活的。不像optimizer states，gradients和parameters对模型更新是必须的，activation只是起到加速梯度计算的作用。因此，在哪几层保存activation，保存哪些activation都是可以灵活设置的。&lt;/p&gt;
&lt;p&gt;ZeRO-Offload&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;forward和backward计算量高，因此和它们相关的部分，例如参数W（fp16），activation，就全放入GPU。&lt;/li&gt;
&lt;li&gt;update的部分计算量低，因此和它相关的部分，全部放入CPU中。例如W(fp32)，optimizer states（fp32）和gradients(fp16)等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;tp&#34;&gt;TP
&lt;/h4&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/622212228&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：张量模型并行(TP)，Megatron-LM&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在之前的内容中，已经介绍过流水线并行(PP)、数据并行(DP，DDP和ZeRO)。下面将要介绍最重要，也是目前基于Transformer做大模型预训练最基本的并行范式：来自NVIDIA的张量模型并行(TP)。它的基本思想就是把模型的参数纵向切开，放到不同的GPU上进行独立计算，然后再做聚合。&lt;/p&gt;
&lt;h4 id=&#34;关于随机种子设定的一般结论&#34;&gt;关于随机种子设定的一般结论
&lt;/h4&gt;&lt;p&gt;一般在TP/PP组内，设定不同的随机种子。而在DP组内，设定相同的随机种子。这只是一个一般结论，我们可以根据实际情况去调整&lt;/p&gt;
&lt;h4 id=&#34;杂谈&#34;&gt;杂谈
&lt;/h4&gt;&lt;p&gt;下划线(_)开头表示Python中的私有变量, 但私有变量在Python中不存在, 只需遵循一些规范即可。语言本身没有任何限制&lt;/p&gt;
&lt;h3 id=&#34;面向进程编程&#34;&gt;面向进程编程
&lt;/h3&gt;&lt;p&gt;整份脚本处理的是发生在1个进程上的事情。这样做的好处是，我们只需要维护1份脚本，然后将其发去不同机器的各张卡上执行，就能实现全局的并行。&lt;/p&gt;
&lt;h3 id=&#34;megatron&#34;&gt;Megatron
&lt;/h3&gt;&lt;p&gt;Megatron还是要看的&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/613196255&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：流水线并行（Pipeline Parallelism），以Gpipe为例&lt;/a&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/617133971&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：数据并行上篇(DP, DDP与ZeRO)&lt;/a&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/618865052&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：数据并行下篇(DeepSpeed ZeRO，零冗余优化)&lt;/a&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/622212228&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：张量模型并行(TP)，Megatron-LM&lt;/a&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/629121480&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型系列之：Megatron源码解读1，分布式环境初始化&lt;/a&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/634377071&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练之：Megatron源码解读2，模型并行&lt;/a&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/662700424&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练系列之：Megatron源码解读3，分布式混合精度训练&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;pretrain部分code大致流程&#34;&gt;pretrain部分code大致流程
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;def pretrain(
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    train_valid_test_dataset_provider,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    model_provider,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    forward_step_func,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    valid_forward_step_func=None,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    extra_args_provider=None,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    args_defaults={},
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;):  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # 1.初始化分布式环境(源码解读1内容)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    initialize_megatron(
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        extra_args_provider=extra_args_provider, args_defaults=args_defaults
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    )
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # 2、模型并行：定义模型架构，并切割模型（本文重点）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # 3、构造train/val/test数据集（下一篇将讲述）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ... (
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            train_data_iterator,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            valid_data_iterator,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            test_data_iterator,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ) = build_train_valid_test_data_iterators(train_valid_test_dataset_provider) 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # 4、训练（下下一篇将讲述）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    iteration = train(
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            forward_step_func,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            valid_forward_step_func,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            model,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            optimizer,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            lr_scheduler,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            train_data_iterator,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            valid_data_iterator,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        )
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;crossentropy&#34;&gt;CrossEntropy
&lt;/h4&gt;&lt;p&gt;在语言模型训练中，我们需要计算预测分布与真实标签之间的交叉熵损失。对于单个样本，交叉熵损失定义为：&lt;/p&gt;
$$
L = -\log P(y|x) = -\log\left(\frac{e^{s_y}}{\sum_{j=1}^{V} e^{s_j}}\right) = \log\left(\sum_{j=1}^{V} e^{s_j}\right) - s_y
$$&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s = [s_1, s_2, \ldots, s_V]$ 是模型输出的 logits（未归一化的对数概率）&lt;/li&gt;
&lt;li&gt;$V$ 是词汇表大小&lt;/li&gt;
&lt;li&gt;$y$ 是真实标签&lt;/li&gt;
&lt;li&gt;$s_y$ 是真实类别对应的 logit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;数值稳定性处理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了数值稳定性，我们在计算 softmax 前先减去最大值：&lt;/p&gt;
$$
\text{logits}&#39; = s - \max(s)
$$&lt;p&gt;这样做的理由：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;防止 $\exp(s)$ 溢出&lt;/li&gt;
&lt;li&gt;不改变 softmax 结果（分子分母同时乘以 $e^{-\max(s)}$）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;词汇表并行（Vocab Parallel）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在张量并行中，词汇表被切分到多个 GPU 上：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设有 $N$ 个 GPU，词汇表大小为 $V$&lt;/li&gt;
&lt;li&gt;每个 GPU 维护 $V/N$ 个词的 logits&lt;/li&gt;
&lt;li&gt;需要通过通信（AllReduce）来计算全局的 softmax 和 loss&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;113
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;114
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;115
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;116
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;117
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;118
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;119
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;120
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;121
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;122
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;123
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;124
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;125
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;126
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;127
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;128
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;129
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;130
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;131
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;132
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;133
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;134
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;135
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;136
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;137
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;138
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;139
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;140
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;141
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;142
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;143
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;144
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;145
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;146
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;147
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;148
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;149
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;150
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;151
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;152
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;153
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;154
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;155
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;156
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;157
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;158
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;159
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;160
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;161
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;162
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;163
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;164
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;165
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;166
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;167
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;168
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;169
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;170
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;171
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;172
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;173
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;174
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;175
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;176
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;177
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;178
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;179
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;180
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;181
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;182
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;183
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;184
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;185
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;186
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;187
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;188
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;189
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;190
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;191
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;192
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;193
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;194
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;195
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;196
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;197
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;198
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;199
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;200
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;201
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;202
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;_VocabParallelCrossEntropy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;autograd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@staticmethod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        前向传播：计算词汇表并行下的交叉熵损失
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        输入：
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - vocab_parallel_logits: [batch_size, seq_len, partition_vocab_size]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;          当前 GPU 上维护的部分词汇表 logits
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - target: [batch_size, seq_len]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;          真实标签（词汇表索引）
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        输出：
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - loss: [batch_size, seq_len]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;          每个位置的交叉熵损失
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第一步：数值稳定性处理 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 在词汇表维度上找到最大值（只在当前 GPU 的分区上找）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# logits_max: [batch_size, seq_len]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：m_i = max(s_i) 其中 s_i 是第 i 个样本的 logits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;logits_max&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 通过 AllReduce 获取全局最大值（跨所有 GPU）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 这样确保所有 GPU 使用相同的最大值进行归一化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：m_global = max(m_1, m_2, ..., m_N) 其中 N 是 GPU 数量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distributed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_reduce&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;logits_max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;op&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distributed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReduceOp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MAX&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_tensor_model_parallel_group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 减去最大值，实现数值稳定&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# logits&amp;#39; = logits - max(logits)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 这样可以防止 exp(logits) 溢出，同时不改变 softmax 结果&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：s&amp;#39;_ij = s_ij - m_global&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sub_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logits_max&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unsqueeze&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第二步：确定当前 GPU 的词汇表范围 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 获取当前 GPU 负责的词汇表索引范围&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 例如：V=10000, N=4, rank=0 -&amp;gt; [0, 2500), rank=1 -&amp;gt; [2500, 5000), ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;get_vocab_range&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VocabUtility&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vocab_range_from_per_partition_vocab_size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;partition_vocab_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 当前 GPU 的词汇表分区大小&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;rank&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_tensor_model_parallel_rank&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 当前 GPU 的 rank&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;world_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_tensor_model_parallel_world_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 总 GPU 数量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;vocab_start_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_end_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_vocab_range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;partition_vocab_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rank&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;world_size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第三步：创建目标掩码 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 判断哪些目标在当前 GPU 的词汇表范围内&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# target_mask=True 表示目标不在当前 GPU 的词汇表范围内&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：mask_i = 1 if (target_i &amp;lt; start) or (target_i &amp;gt;= end), else 0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;target_mask&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_start_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_end_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 将全局目标索引转换为当前 GPU 的局部索引&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：target&amp;#39;_i = target_i - vocab_start_index&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;masked_target&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clone&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_start_index&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 将不在当前范围内的目标设为 0（之后会被 mask 掉）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;masked_target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第四步：提取目标位置的 logit ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 将 logits 展平为 2D：[batch_size * seq_len, partition_vocab_size]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 将 target 展平为 1D：[batch_size * seq_len]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 这样方便使用高级索引&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;logits_2d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;partition_vocab_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;masked_target_1d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;masked_target&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 创建行索引 [0, 1, 2, ..., batch_size * seq_len - 1]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;arange_1d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;start&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logits_2d&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logits_2d&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 提取每个样本对应目标位置的 logit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：s&amp;#39;_target = logits[arange_1d, masked_target_1d]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 即取出每个样本在其目标词汇位置的 logit 值&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;predicted_logits_1d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;logits_2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange_1d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;masked_target_1d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;predicted_logits_1d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predicted_logits_1d&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clone&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contiguous&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 恢复原始形状：[batch_size, seq_len]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;predicted_logits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predicted_logits_1d&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view_as&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 将不在当前 GPU 范围内的目标的 logit 设为 0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 这样做是因为之后会通过 AllReduce 求和，只需要贡献自己的部分&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;predicted_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 通过 AllReduce 从所有 GPU 收集目标的 logit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 每个 GPU 只贡献自己分区内的目标 logit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 最终得到所有目标位置的完整 logit 值&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：s_y = Σ(s&amp;#39;_y_i) 对所有 GPU 求和&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distributed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_reduce&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;predicted_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;op&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distributed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReduceOp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SUM&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_tensor_model_parallel_group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第五步：计算归一化项（log-sum-exp）============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 计算 exp(logits&amp;#39;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：e&amp;#39;_ij = exp(s&amp;#39;_ij)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;exp_logits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exp_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 在当前 GPU 的词汇表维度上求和&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：E&amp;#39;_i = Σ(e&amp;#39;_ij) 对当前 GPU 的词汇表维度求和&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;sum_exp_logits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp_logits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 通过 AllReduce 从所有 GPU 收集完整的指数和&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：E_i = Σ(E&amp;#39;_i) 对所有 GPU 求和&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 这就是 softmax 的分母：Σ(exp(s_j))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distributed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_reduce&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;sum_exp_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;op&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distributed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReduceOp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SUM&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_tensor_model_parallel_group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第六步：计算最终损失 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 交叉熵损失：L = log(sum(exp(logits))) - predicted_logit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：L = log(E_i) - s_y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 这对应：L = log(Σ(exp(s_j))) - s_y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 即：L = -log(exp(s_y) / Σ(exp(s_j))) = -softmax_y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum_exp_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predicted_logits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第七步：保存反向传播所需的中间变量 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 计算 softmax 并保存，用于反向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：softmax_ij = exp(s&amp;#39;_ij) / E_i&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;exp_logits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;div_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum_exp_logits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unsqueeze&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 保存 softmax、target_mask 和 masked_target_1d 用于反向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;save_for_backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exp_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;masked_target_1d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@staticmethod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;grad_output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        反向传播：计算交叉熵损失对 logits 的梯度
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        数学推导：
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        前向传播：L = log(Σ(exp(s_j))) - s_y
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        对 logits 的梯度：
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        ∂L/∂s_i = softmax_i - 1_{i=y}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        其中：
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - softmax_i = exp(s_i) / Σ(exp(s_j))
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - 1_{i=y} 是指示函数，当 i=y 时为 1，否则为 0
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        在词汇表并行的场景下：
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - 当前 GPU 只计算自己分区内的梯度
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - 对于目标位置：grad = softmax - 1
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        - 对于非目标位置：grad = softmax
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第一步：恢复前向传播保存的中间变量 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# softmax: [batch_size, seq_len, partition_vocab_size]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# target_mask: [batch_size, seq_len] (布尔掩码)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# masked_target_1d: [batch_size * seq_len] (局部索引)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;softmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;masked_target_1d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;saved_tensors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第二步：初始化梯度 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 交叉熵损失的梯度基础是 softmax 值&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 对于所有位置，梯度从 softmax 开始&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：∂L/∂s_i = softmax_i （基础项）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;grad_input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;softmax&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 为了方便索引，转换为 2D 格式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# grad_2d: [batch_size * seq_len, partition_vocab_size]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;partition_vocab_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;softmax&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;grad_2d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;grad_input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;partition_vocab_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第三步：处理目标位置的梯度 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 对于目标位置，需要减去 1（指示函数）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：∂L/∂s_y = softmax_y - 1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 其中 1 是真实标签的指示函数 1_{i=y}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 创建行索引&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;arange_1d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;start&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad_2d&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad_2d&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 对目标位置的梯度进行调整：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 1. 如果目标在当前 GPU 的词汇表范围内（target_mask=False）：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;#    grad = softmax - 1 （减 1）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 2. 如果目标不在当前范围内（target_mask=True）：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;#    grad = softmax - 0 （不减 1，因为目标在其他 GPU 上）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ∂L/∂s_y = softmax_y - (1 - mask_y)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 其中 mask_y = 1 表示目标不在当前 GPU，mask_y = 0 表示目标在当前 GPU&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;grad_2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange_1d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;masked_target_1d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_mask&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# ============ 第四步：乘以上层梯度 ============&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 根据链式法则，需要乘以损失对输出的梯度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 数学表达：∂L_total/∂s = (∂L/∂s) × (∂L_total/∂L)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 其中 grad_output 是 ∂L_total/∂L&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;grad_input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mul_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad_output&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unsqueeze&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 返回梯度（第二个输入 target 不需要梯度，返回 None）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;grad_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;vocab_parallel_cross_entropy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Helper function for the cross entropy.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;_VocabParallelCrossEntropy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vocab_parallel_logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;精度问题&#34;&gt;精度问题
&lt;/h4&gt;&lt;p&gt;从占用存储角度看，fp16占据2 bytes，bf16占据2 bytes，fp32占据4 bytes&lt;br&gt;
从数值表达范围来看：fp32 = bf16 &amp;gt; fp16&lt;br&gt;
从数值表达精度来看：fp32 &amp;gt; fp16 &amp;gt; bf16&lt;/p&gt;
&lt;p&gt;最好理解每一部分精度转换的原因和整个流程，算是基本功&lt;/p&gt;
&lt;p&gt;老样子，放一些写的好的文章可以学一学&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/662700424&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;图解大模型训练系列之：Megatron源码解读3，分布式混合精度训练&lt;/a&gt;&lt;br&gt;
megatron/training.py的pretrain 函数。其中，函数setup_model_and_optimizer调用了optimizer/&lt;strong&gt;init&lt;/strong&gt;.py/下的get_megatron_optimizer，因此它就是混合精度训练的入口函数&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/624740065&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;分析transformer模型的参数量、计算量、中间激活、KV cache&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;两种做Loss Scale的方法：常量损失放大和动量损失放大&lt;/p&gt;
&lt;h3 id=&#34;deepspeed&#34;&gt;DeepSpeed
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/transformers/deepspeed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DeepSpeed官方文档&lt;/a&gt;👈官方文档&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.deepspeed.ai/docs/config-json/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DeepSpeed配置JSON&lt;/a&gt;👈使用只需要JSON配置文件&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=mpuRca2UZtI&amp;amp;t=2925s&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;【利用多張GPU訓練大型語言模型】 - YouTube&lt;/a&gt;👈李宏毅老师YouTube视频讲解（约一个小时）&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/spaces/nanotron/ultrascale-playbook&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Ultra-Scale Playbook:Training LLMs on GPU Clusters&lt;/a&gt;👈并行训练高质参考资料&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hugging face经常有高质量实验总结，可以多关注一下&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;一开始会有batch-size个prompt去做rollout，每个prompt rollout出n个response，之后每mini-batch-size个prompt及其rollout出来的response会去做一次梯度下降，batch-size / mini-batch-size次梯度下降之后一个step结束&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Batch Size Related Parameters
&lt;strong&gt;train_batch_size&lt;/strong&gt; = &lt;strong&gt;train_micro_batch_size_per_gpu&lt;/strong&gt; * &lt;strong&gt;gradient_accumulation_steps&lt;/strong&gt; * &lt;strong&gt;number of GPUs&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;train_batch_size: [integer]
代表着one step.Example:32&lt;/li&gt;
&lt;li&gt;train_micro_batch_size_per_gpu: [integer]
一次更新的batch_size，所以叫micro_batch_size.&lt;/li&gt;
&lt;li&gt;gradient_accumulation_steps: [integer]
积累几次&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一开始会有batch-size个prompt去做rollout，每个prompt rollout出n个response，之后每mini-batch-size个prompt及其rollout出来的response会去做一次梯度下降，batch-size / mini-batch-size次梯度下降之后一个step结束&lt;/p&gt;
&lt;h3 id=&#34;监控平台&#34;&gt;监控平台
&lt;/h3&gt;&lt;p&gt;可以使用TensorBoard,wandb,Comet等，因为个人使用所以只介绍swanlab(wandb的国内镜像)&lt;br&gt;
注册登录，设置 project_name 和 experiment_name 就可以在电脑上/手机上看了&lt;br&gt;
很好用的监控平台！&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://docs.swanlab.cn/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;swanlab官方文档&lt;/a&gt;👈官方文档&lt;/p&gt;
&lt;h3 id=&#34;verl框架使用方法快速上手&#34;&gt;veRL框架使用方法/快速上手
&lt;/h3&gt;&lt;p&gt;知乎上收藏了一些轮椅教程&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/29149216967&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenRLHF&amp;amp;Verl参数转换指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;更深入的：&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/24682036412&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HybridFlow / veRL 原文浅析&lt;/a&gt;很干，对system理解有很大帮助&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/27676081245&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[AI Infra] VeRL 框架入门&amp;amp;代码带读&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/30876678559&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;从零开始的verl框架解析&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>NLP</title>
        <link>http://localhost:1313/p/nlp/</link>
        <pubDate>Mon, 19 Jan 2026 10:00:00 +0800</pubDate>
        
        <guid>http://localhost:1313/p/nlp/</guid>
        <description>&lt;h2 id=&#34;生成式人工智慧與機器學習導論2025第3講解剖大型語言模型representation&#34;&gt;【生成式人工智慧與機器學習導論2025】第3講：解剖大型語言模型representation
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Xnil63UDW2o&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=Xnil63UDW2o&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Token Embedding 是在Layer 1输入的那个， Contextualized Embedding(也就是我们说的representation表征) 指的是经过Layer 1输出的那个.&lt;/p&gt;
&lt;p&gt;Representation Engineering, Activation Engineering, Activating Steering&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;logit-lens&#34;&gt;Logit Lens
&lt;/h3&gt;&lt;p&gt;对每一层进行 Unembedding ,可以看每一层的思考所对应的文字，窥探语言模型的思考过程&lt;/p&gt;
&lt;h3 id=&#34;patchscopes&#34;&gt;Patchscopes
&lt;/h3&gt;&lt;p&gt;把一个向量（一个token/字）替换成一句话&lt;/p&gt;
&lt;h3 id=&#34;layer解读使用transformer架构的解读&#34;&gt;Layer解读（使用Transformer架构的解读）
&lt;/h3&gt;&lt;p&gt;Layer 中还有 Layer.&lt;/p&gt;
&lt;p&gt;首先过 Self-attention Layer (attention layer), 考虑上下文就是因为 attention layer, 输出经过几个 Feed Forward Layer&lt;/p&gt;
&lt;p&gt;典中典，要求手撕 Attention Layer ,&lt;/p&gt;
&lt;p&gt;自己跟自己也要进行dot product&lt;/p&gt;
&lt;p&gt;dot product 叫 Attention weight, 要所有的 weight 过 Softmax&lt;/p&gt;
&lt;h4 id=&#34;positional-embedding&#34;&gt;Positional Embedding
&lt;/h4&gt;&lt;p&gt;Llama 用 Rope , 旋转位置编码, 为了把位置的咨询加入到计算中&lt;/p&gt;
&lt;h4 id=&#34;multi-head-attention&#34;&gt;Multi-head Attention
&lt;/h4&gt;&lt;p&gt;每一个 head 的作用不一样
&lt;img src=&#34;http://localhost:1313/p/nlp/head1.png&#34;
	width=&#34;1920&#34;
	height=&#34;1080&#34;
	srcset=&#34;http://localhost:1313/p/nlp/head1_hu_5c2f61de8fa1895a.png 480w, http://localhost:1313/p/nlp/head1_hu_7082b3b93c16b72d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/nlp/head2.png&#34;
	width=&#34;1920&#34;
	height=&#34;1080&#34;
	srcset=&#34;http://localhost:1313/p/nlp/head2_hu_83133a53ace293d4.png 480w, http://localhost:1313/p/nlp/head2_hu_55132687d139d9b4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/nlp/head_sum.png&#34;
	width=&#34;1920&#34;
	height=&#34;1080&#34;
	srcset=&#34;http://localhost:1313/p/nlp/head_sum_hu_e51fd46eca1988c9.png 480w, http://localhost:1313/p/nlp/head_sum_hu_4be7b5a6e054e9f4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;目前的语言模型大多数都是 Causal Attention, 这样计算方便(Autogressive)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/nlp/neuron.png&#34;
	width=&#34;1920&#34;
	height=&#34;1080&#34;
	srcset=&#34;http://localhost:1313/p/nlp/neuron_hu_4bcc0684b5ad4793.png 480w, http://localhost:1313/p/nlp/neuron_hu_3fd78a0647b41cb5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;实做环节&#34;&gt;实做环节
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;model.num_parameters()会告诉我们 model 的参数量
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;深度学习模型的参数通常以多个矩阵 (Matrix) 和向量 (Vector) 的形式存储。向量、矩阵等统称为张量(Tensor)&lt;/p&gt;
&lt;p&gt;Llama3 有28层，Gemma4B 有44层&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;model.state_dict() 可以实际把参数拿出来看看
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;一文看懂大模型推理过程&#34;&gt;一文看懂大模型推理过程
&lt;/h2&gt;&lt;p&gt;内容特别简单，适合感兴趣的小白简单阅读&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/1931115470431454357&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/1931115470431454357&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;ttfttime-to-first-token&#34;&gt;TTFT（Time To First Token）
&lt;/h3&gt;&lt;p&gt;Tokenizer + Prefill&lt;/p&gt;
&lt;p&gt;一般是推理过程里耗时最多的一步，尤其当输入内容多、模型参数大时&lt;/p&gt;
&lt;h3 id=&#34;tpottime-per-output-token&#34;&gt;TPOT（Time Per Output Token）
&lt;/h3&gt;&lt;p&gt;Decoding Loop中的每一次推理&lt;/p&gt;
&lt;p&gt;模型每“说”一个字/词的时间&lt;br&gt;
TPOT 越低，响应越流畅。&lt;br&gt;
但模型越大，TPOT 越高；&lt;br&gt;
GPU 负载越高、token越复杂，TPOT 也会变慢。&lt;/p&gt;
&lt;h3 id=&#34;itlinference-time-latency&#34;&gt;ITL（Inference Time Latency）
&lt;/h3&gt;&lt;p&gt;Tokenizer + Prefill + Decoding Loop + Post-processing&lt;/p&gt;
&lt;p&gt;ITL = 从你提问到回答完整输出的总耗时。&lt;/p&gt;
&lt;p&gt;它 = TTFT + n × TPOT&lt;/p&gt;
&lt;h2 id=&#34;engram&#34;&gt;Engram
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/1994328242795090231&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/1994328242795090231&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;微调技术&#34;&gt;微调技术
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/636481171&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/636481171&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-big-llm-architecture-comparison&#34;&gt;The Big LLM Architecture Comparison
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;understanding-reasoning-llms&#34;&gt;Understanding Reasoning LLMs
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>SJTU-research-intern</title>
        <link>http://localhost:1313/p/sjtu-research-intern/</link>
        <pubDate>Thu, 23 Oct 2025 10:00:00 +0800</pubDate>
        
        <guid>http://localhost:1313/p/sjtu-research-intern/</guid>
        <description>&lt;img src="http://localhost:1313/p/sjtu-research-intern/SJTU.jpg" alt="Featured image of post SJTU-research-intern" /&gt;&lt;h4 id=&#34;20251023&#34;&gt;2025/10/23
&lt;/h4&gt;&lt;p&gt;实习第一天&lt;/p&gt;
&lt;h4 id=&#34;20251027&#34;&gt;2025/10/27
&lt;/h4&gt;&lt;p&gt;周六凌晨开始跑的论文复现，当时为了图速度就没有顾虑太多。今天学姐问我一些实验过程中的指标变化等等来对比idea的实验是否正常工作，只能回去手动复制tmux里面的内容。&lt;/p&gt;
&lt;p&gt;每跑一次实验都要记得能留日志就留日志，能上wandb/Swanlab就上，跑完的实验数据等等都要保存，留着。后续可能会用到。&lt;/p&gt;
&lt;p&gt;千万不要一味地追求速度，图省事！&lt;/p&gt;
&lt;p&gt;与此同时解决了submodule问题，具体的流程大致为删掉子仓库中的.git，移除本地缓存（觉得他是子module），从.gitmodule中移除（当然我本地没有）。&lt;/p&gt;
&lt;p&gt;之前也解决了关于代码冲突的问题（需要手动进行修改），比如在git pull中是常见问题，大致进一步又了解了，准备后面有时间写一个关于这种多人协作常出现的问题，要注意的事项以及如何解决&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Flash-Attention安装常见问题及其解决方案</title>
        <link>http://localhost:1313/p/flash-attention%E5%AE%89%E8%A3%85%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
        <pubDate>Thu, 09 Oct 2025 10:00:00 +0800</pubDate>
        
        <guid>http://localhost:1313/p/flash-attention%E5%AE%89%E8%A3%85%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
        <description>&lt;h1 id=&#34;解决方案&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/coldchair/p/18615384&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;解决方案&lt;/a&gt;👈
&lt;/h1&gt;&lt;h2 id=&#34;方法1就完全work&#34;&gt;方法1就完全work!
&lt;/h2&gt;&lt;h2 id=&#34;注意版本冲突问题如果不确定可以多问问之前工作的环境或者clone几个备份&#34;&gt;注意版本冲突问题，如果不确定可以多问问之前工作的环境或者clone几个备份！
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>Ray分布式训练因进程耗尽导致SSH断开连接</title>
        <link>http://localhost:1313/p/ray%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%9B%A0%E8%BF%9B%E7%A8%8B%E8%80%97%E5%B0%BD%E5%AF%BC%E8%87%B4ssh%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5/</link>
        <pubDate>Thu, 09 Oct 2025 10:00:00 +0800</pubDate>
        
        <guid>http://localhost:1313/p/ray%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%9B%A0%E8%BF%9B%E7%A8%8B%E8%80%97%E5%B0%BD%E5%AF%BC%E8%87%B4ssh%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5/</guid>
        <description>&lt;img src="http://localhost:1313/p/ray%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%9B%A0%E8%BF%9B%E7%A8%8B%E8%80%97%E5%B0%BD%E5%AF%BC%E8%87%B4ssh%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5/Ray.jpg" alt="Featured image of post Ray分布式训练因进程耗尽导致SSH断开连接" /&gt;&lt;h1 id=&#34;问题详情--解决方案&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/ray-project/ray/issues/57556&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;问题详情 + 解决方案&lt;/a&gt;👈
&lt;/h1&gt;</description>
        </item>
        <item>
        <title>STILL3</title>
        <link>http://localhost:1313/p/still3/</link>
        <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/still3/</guid>
        <description>&lt;p&gt;重新认真地读一遍STILL3(LLMs慢思维技术报告III )，补充知识点&lt;/p&gt;
&lt;h1 id=&#34;an-empirical-study-on-eliciting-and-improving-r1-like-reasoning-models&#34;&gt;An Empirical Study on Eliciting and Improving R1-like Reasoning Models
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/RUCAIBox/Slow_Thinking_with_LLMs&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;慢思考模型仓库&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;缺乏可验证问题的领域:如DeepSeek-R1,基于规则和训练的奖励模型的联合使用&lt;/p&gt;
&lt;p&gt;随着训练的进行，可以观察到三个主要特征：&lt;strong&gt;增加训练奖励&lt;/strong&gt;、&lt;strong&gt;增加响应长度&lt;/strong&gt;和&lt;strong&gt;涌现推理模式&lt;/strong&gt;。些因素是扩大强化学习训练成功的&lt;strong&gt;关键指标&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在本报告中，首先深入研究了强化学习&lt;strong&gt;设置对训练效果的影响&lt;/strong&gt;。接下来，通过强化学习训练直接激励基础模型发展复杂的推理能力，&lt;strong&gt;观察到模型逐渐花费更多的时间“思考”并表现出高级推理行为（例如，验证或反思）&lt;/strong&gt;。最后，为了进一步增强微调模型的推理能力，探索了&lt;strong&gt;强化学习和工具增强作为提高模型推理性能的策略&lt;/strong&gt;，在小型（1.5B）和中型LLM（32B）中都取得了显著的改进。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;on-policy learning strategy被证明是关键因素！&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;response length是RL训练成功的重要指标，这是结果，不是原因&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;设计专门的奖励函数来鼓励模型产生更长的响应可能会导致奖励黑客攻击等问题，这不能从本质上增强模型的推理能力&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;无论是短CoT还是长CoT，还是蒸馏过的模型，强化学习都可以提高能力&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过fine-tuning，LRM可以获得操纵外部工具的能力，从而提高模型的性能。这种能力只需少量高质量的训练实例即可激活。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/RUCAIBox/Slow_Thinking_with_LLMs&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;复现点这里找资源&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;实验设置&#34;&gt;实验设置
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/still3/config.jpg&#34;
	width=&#34;735&#34;
	height=&#34;494&#34;
	srcset=&#34;http://localhost:1313/p/still3/config_hu_70515ab103a2c7ca.jpg 480w, http://localhost:1313/p/still3/config_hu_ec0a84f70a7f3d4a.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;config&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;148&#34;
		data-flex-basis=&#34;357px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;训练框架&#34;&gt;训练框架
&lt;/h2&gt;&lt;p&gt;OpenRLHF和veRL&lt;/p&gt;
&lt;h2 id=&#34;骨干模型&#34;&gt;骨干模型
&lt;/h2&gt;&lt;p&gt;各种版本的QWEN2.5模型&lt;/p&gt;
&lt;p&gt;DEEPSEK-R1-DISTILL系列的1.5B和32B QWEN2.5&lt;/p&gt;
&lt;p&gt;在微调模型上进行实验，微调数据由自己合成。&lt;/p&gt;
&lt;h2 id=&#34;训练数据&#34;&gt;训练数据
&lt;/h2&gt;&lt;h4 id=&#34;多样性&#34;&gt;多样性
&lt;/h4&gt;&lt;p&gt;AIME,MATH,NuminaMath,Open Reasoner Zero&lt;/p&gt;
&lt;h4 id=&#34;可验证性&#34;&gt;可验证性
&lt;/h4&gt;&lt;p&gt;删除了多选题，证明题，概念题，开放式问题和有多个子问题的问题&lt;br&gt;
再把答案不可能的数据删掉&lt;/p&gt;
&lt;h4 id=&#34;困难程度&#34;&gt;困难程度
&lt;/h4&gt;&lt;p&gt;基于模型的过滤，QWEN-7B-INSTRUCT正确率过高或者零通过率的题目删掉&lt;/p&gt;
&lt;p&gt;最后剩下90k个examples&lt;/p&gt;
&lt;h2 id=&#34;reward-design&#34;&gt;Reward Design
&lt;/h2&gt;&lt;p&gt;设计并验证了一组不同的奖励，并分析了它们对模型性能的影响，包括输出奖励、格式奖励、长度奖励和动作奖励。&lt;/p&gt;
&lt;p&gt;输出奖励评估 最终答案是否与ground truth匹配。如果答案正确，我们将奖励设置为1，否则设置为0。&lt;/p&gt;
&lt;p&gt;如果模型未能将其最终答案放入\boxed{}中，则奖励设置为0。&lt;br&gt;
使用格式奖励来指导基础模型正确构建其响应。&lt;/p&gt;
&lt;p&gt;探索了新的辅助奖励，包括鼓励更长反应的长度奖励和激励复杂推理行为的行动奖励。&lt;/p&gt;
&lt;h2 id=&#34;evaluation-benchmarks&#34;&gt;Evaluation Benchmarks
&lt;/h2&gt;&lt;p&gt;评估了各种数学推理任务的模型性能，包括MATH-OAI[13]、AIME、Omni-MATH[17]、LiveAOP[18]和HMMT。&lt;br&gt;
iveAOP利用AoPS论坛的帖子创建了一个由3863个示例组成的抗污染评估集。&lt;/p&gt;
&lt;h2 id=&#34;compute-environment&#34;&gt;Compute Environment
&lt;/h2&gt;&lt;p&gt;实验主要在DataCanvas的旗舰计算编排平台Alaya NeW AI操作系统上进行。&lt;/p&gt;
&lt;h1 id=&#34;rl-experiments-on-the-base-model&#34;&gt;RL Experiments on the Base Model
&lt;/h1&gt;&lt;p&gt;直接将RL应用于预训练的基础模型进行实验，而不需要任何中间的SFT阶段。这种方法旨在探索LLM是否可以通过纯粹的RL驱动的自我提升来自主发展推理能力&lt;/p&gt;
&lt;h4 id=&#34;考察了四个关键维度&#34;&gt;考察了四个关键维度
&lt;/h4&gt;&lt;h3 id=&#34;1训练超参数的影响&#34;&gt;1.训练超参数的影响
&lt;/h3&gt;&lt;h3 id=&#34;2比较不同的基础模型并将其与具有短cot推理能力的微调模型进行对标来分析骨干模型的效果&#34;&gt;2.比较不同的基础模型并将其与具有短CoT推理能力的微调模型进行对标，来分析骨干模型的效果
&lt;/h3&gt;&lt;h3 id=&#34;3快速设计对rl训练中基础模型推理能力的影响&#34;&gt;3.快速设计对RL训练中基础模型推理能力的影响
&lt;/h3&gt;&lt;h3 id=&#34;4代表性推理模式如验证或反射的出现&#34;&gt;4.代表性推理模式（如验证或反射）的出现
&lt;/h3&gt;&lt;h2 id=&#34;exploring-the-settings-of-rl-training&#34;&gt;Exploring the Settings of RL Training
&lt;/h2&gt;&lt;p&gt;重点分析两个关键方面的影响：超参数和训练提示。&lt;/p&gt;
&lt;h3 id=&#34;influence-of-training-hyper-parameters&#34;&gt;Influence of Training Hyper-parameters
&lt;/h3&gt;&lt;h4 id=&#34;train-batch-sizetbs&#34;&gt;Train Batch Size(TBS)
&lt;/h4&gt;&lt;p&gt;TBS=128 v.s.1024&lt;br&gt;
更大的TBS可以显著提高训练效率，使模型在早期训练阶段能够快速提高性能。此外，与较小批量相比，较大批量的训练表现出更大的稳定性，训练指标的波动显著减少&lt;/p&gt;
&lt;h4 id=&#34;learning-strategy-on-policy-vs-off-policy&#34;&gt;Learning Strategy: On-policy vs. Off-policy
&lt;/h4&gt;&lt;p&gt;on-policy 鼓励更多的探索；在训练过程中，模型自然快速地增加了响应长度，而更新较少的非策略学习在长度增长方面遇到了瓶颈&lt;/p&gt;
&lt;h4 id=&#34;rollout-parameters&#34;&gt;Rollout Parameters
&lt;/h4&gt;&lt;p&gt;主要研究两个rollout parameters（rollout times和rollout temperature）&lt;br&gt;
更大的推出数量和更高的温度通常表示更大程度的探索&lt;/p&gt;
&lt;h4 id=&#34;coefficient-of-kl-penalty&#34;&gt;Coefficient of KL Penalty
&lt;/h4&gt;&lt;p&gt;动态KL退火具有很好的综合性&lt;/p&gt;
&lt;h4 id=&#34;effect-of-backbone-models&#34;&gt;Effect of Backbone Models
&lt;/h4&gt;&lt;p&gt;上述实验基于QWEN2.5-7B。此外，还对较小的QWEN2.5-1.5B模型、监督微调QWEN2.5-7B-INSTRUCT模型和数学专用QWEN2.5-math-7B模型进行了实验。&lt;/p&gt;
&lt;p&gt;在上述设置下，我们的实验表明，与QWEN2.5-1.5B相比，QWEN2.5-7B表现出更强的探索能力，并且在强化学习训练中遵循与QWEN2.5.7B-INSTRUCT类似的趋势。&lt;/p&gt;
&lt;h2 id=&#34;impact-of-the-prompt&#34;&gt;Impact of the Prompt
&lt;/h2&gt;&lt;p&gt;使用两种基本模型（即QWEN2.5-1.5B和QWEN2.5-7B）和两种类型的提示进行实验&lt;br&gt;
第一种是短提示，类似于DeepSeek-R1-Zero中使用的提示。此外，为了更好地引出基础模型的推理能力，我们设计了一个新的提示，其中包括关于推理过程的详细说明，称为长提示&lt;/p&gt;
&lt;p&gt;这个新提示保留了对特定推理格式的要求，同时添加了对推理过程的全面描述。这包括在推理过程中可以应用的策略（例如，分析问题、总结发现）以及在整个过程中使用的推荐表达和词汇（例如，“等待”、“替代”）&lt;/p&gt;
&lt;p&gt;在本实验中将learning rate、train batch size、rollout temperature和number of rollout times设置为1×10−6、128、1.0和8，并执行on-policy训练策略。我们将KL penalty和entropy loss的系数设置为0.0，有效地消除了模型上的约束。这使得可以更清楚地观察到各种提示导致的性能差异&lt;/p&gt;
&lt;h3 id=&#34;实验结果&#34;&gt;实验结果
&lt;/h3&gt;&lt;p&gt;对于QWEN2.5-1.5B，在短提示下训练的模型在测试集上的性能高于在长提示上训练的模型。这可能是因为1.5B大小的基本模型容量相对有限，难以遵循详细提示中的复杂说明。&lt;/p&gt;
&lt;p&gt;当在不同的提示下训练时，7B大小的模型在下游任务上显示出类似的性能。然而，在长提示上训练的模型会产生更短的响应，这表明它通过遵守提示中提供的指导方针来学习更有效的推理&lt;/p&gt;
&lt;p&gt;因此，我们得出结论，更详细的提示可以引导模型更有效地思考，提高推理效率。然而，它们不一定能提高下游任务的性能。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>LRM-RL-survey</title>
        <link>http://localhost:1313/p/lrm-rl-survey/</link>
        <pubDate>Wed, 24 Sep 2025 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/lrm-rl-survey/</guid>
        <description>&lt;img src="http://localhost:1313/p/lrm-rl-survey/sky.jpg" alt="Featured image of post LRM-RL-survey" /&gt;&lt;h1 id=&#34;a-survey-of-reinforcement-learning-for-large-reasoning-models&#34;&gt;A Survey of Reinforcement Learning for Large Reasoning Models
&lt;/h1&gt;&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;RL在推进LLM能力的前沿方面取得了显著成功，特别是在解决数学和编码等复杂逻辑任务方面。因此，RL已成为将LLM转化为LRM的基础方法。&lt;/p&gt;
&lt;p&gt;需要探索提高强化学习向人工超级智能（ASI）的可扩展性的策略。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/lrm-rl-survey/history.jpg&#34;
	width=&#34;1313&#34;
	height=&#34;621&#34;
	srcset=&#34;http://localhost:1313/p/lrm-rl-survey/history_hu_fd91b4e2f759ffa.jpg 480w, http://localhost:1313/p/lrm-rl-survey/history_hu_493c3c9057a75b6c.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;这两年的发展&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;507px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/lrm-rl-survey/overview.jpg&#34;
	width=&#34;1304&#34;
	height=&#34;615&#34;
	srcset=&#34;http://localhost:1313/p/lrm-rl-survey/overview_hu_5f42649c3469429c.jpg 480w, http://localhost:1313/p/lrm-rl-survey/overview_hu_9c488682e473c029.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;具体包含的模块&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;508px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;回顾一下大致流程吧！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/lrm-rl-survey/agentProgress.jpg&#34;
	width=&#34;762&#34;
	height=&#34;339&#34;
	srcset=&#34;http://localhost:1313/p/lrm-rl-survey/agentProgress_hu_4d7c597a2ebaeebd.jpg 480w, http://localhost:1313/p/lrm-rl-survey/agentProgress_hu_b9f415b03c60b5a9.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;agentProgress&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;539px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/lrm-rl-survey/LMProgress.jpg&#34;
	width=&#34;479&#34;
	height=&#34;394&#34;
	srcset=&#34;http://localhost:1313/p/lrm-rl-survey/LMProgress_hu_1f5e4f08ac92e4f2.jpg 480w, http://localhost:1313/p/lrm-rl-survey/LMProgress_hu_7cd98ff41913c5e4.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LMProgress&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;121&#34;
		data-flex-basis=&#34;291px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;简单讲解一下rl应用到语言模型的时候这些概念映射到了哪里&#34;&gt;简单讲解一下RL应用到语言模型的时候，这些概念映射到了哪里
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Prompt/Task（x）：对应于初始状态或环境上下文，从数据分布中提取，对应于数据集D。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Policy (πθ):表示语言模型，它根据提示生成一个长度为T的序列，表示为y=（y1，…，yT）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;State (st):定义为提示以及到目前为止生成的令牌，即st=（x，a1:t−1）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Action (at):在步骤t从动作空间A中选择的单元。根据粒度，动作可以是整个序列y（序列级）、∈V处的令牌（令牌级）或 片段&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transition Dynamics (P):在LLM的上下文中，状态转换通常是确定的，因为st+1=[st，at]，其中[·，·]表示字符串连接。当状态包含EOS令牌时，策略将转换为终端状态，这意味着轨迹结束。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reward (R(x, y) or rt):基于动作粒度进行分配，例如，轨迹末端的序列级别R（x，y），每个令牌的令牌级别rt=R（x、a1:t），或每个分段的步长级别rk=R（x、y（1:k））。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Return (G):提示x的整个轨迹y的累积奖励（通常在有限时间内γ=1）。它通过序列级奖励简化为单个标量R（x，y），否则按每个令牌/步骤聚合奖励&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;frontier-models&#34;&gt;Frontier Models
&lt;/h2&gt;&lt;p&gt;按时间顺序排列在三个主要方向上：LRM、agentic LRMs和多模态LRM。&lt;br&gt;
一个大型推理模型，OpenAI的o1[2024]系列，建立了将训练时间RL和测试时间计算扩展到更强大的推理能力的有效性，在数学、编码和科学基准测试方面取得了领先成果。&lt;br&gt;
DeepSeek的旗舰模型R1[2025a]是第一个在基准测试中与o1性能相匹配的开源模型。它采用多阶段训练管道来确保全面的模型能力，并探索了没有监督微调的纯RL路线（即Zero RL）。&lt;br&gt;
其他专有模型发布紧随其后：Claude-3.7-Sonnet[2025a]以混合推理为特色，Gemini 2.0和2.5[2025]引入了更长的上下文长度，Seed Thinking 1.5[2025b]以跨领域的泛化为特色，o3[2025a]系列展示了越来越先进的推理能力。最近，OpenAI推出了他们的第一个开源推理模型gpt-oss-120b[2025a]，随后推出了GPT5[2025a]，这是他们迄今为止最强大的人工智能系统，可以在高效模型和更深入的推理模型gpt-5思维之间灵活切换。并行的开源努力继续扩大了格局。在Qwen家族中，QwQ-32B[2025g]与R1的表现相匹配，其次是Qwen3[2025a]系列，代表性型号Qwen3-235B进一步提高了基准分数。Skywork-OR1[2025d]模型套件基于R1蒸馏模型，并通过有效的数据混合和算法创新实现了可扩展的RL训练。Minimax-M1[2025a]是第一个有效地将混合注意力引入尺度RL的模型。其他作品包括Llama Nemotron Ultra[2025]，旨在平衡准确性和效率；Magistral 24B[2025]，通过RL从头开始训练，而不是从先前的模型中提炼；以及种子OSS[2025a]，强调长上下文推理能力。等等&amp;hellip;&lt;/p&gt;
&lt;p&gt;过去的一年发展迅速啊！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/lrm-rl-survey/models.jpg&#34;
	width=&#34;1297&#34;
	height=&#34;677&#34;
	srcset=&#34;http://localhost:1313/p/lrm-rl-survey/models_hu_8b9f390b6a5af111.jpg 480w, http://localhost:1313/p/lrm-rl-survey/models_hu_2544bbbdc362202a.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;models&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;459px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;foundational-components&#34;&gt;Foundational Components
&lt;/h2&gt;&lt;h3 id=&#34;reward-design&#34;&gt;Reward Design
&lt;/h3&gt;&lt;p&gt;在1.1中，我们对LRM RL中的奖励设计进行了全面的考察。从可验证的奖励开始，DeepSeek-R1的成功就是例证，它通过可验证的奖励机制证明了RL的可扩展性。&lt;/p&gt;
&lt;p&gt;在1.2中，我们考察生成性奖励，其中模型用于验证或直接生成奖励信号。&lt;/p&gt;
&lt;p&gt;然而，可验证和生成性奖励通常都表示为稀疏的数值反馈。一个重要的互补维度在于奖励信号的密度。&lt;/p&gt;
&lt;p&gt;1.3相应地考察了包含密集奖励的方法。另一个分类轴涉及奖励是根据外部真实情况计算的，还是由模型直接估计的。&lt;/p&gt;
&lt;p&gt;这一区别促使我们在1.4中讨论无监督奖励。&lt;/p&gt;
&lt;p&gt;在这四个类别的基础上，我们在1.5中转向奖励塑造，在那里我们分析了组合或转换不同奖励信号以促进学习的策略。&lt;/p&gt;
&lt;h3 id=&#34;verifiable-rewards&#34;&gt;Verifiable Rewards
&lt;/h3&gt;&lt;p&gt;基于规则的奖励通过利用准确性和格式检查，为RL提供可扩展和可靠的训练信号，特别是在数学和代码任务中。&lt;/p&gt;
&lt;p&gt;Verifier定律强调，具有清晰和自动验证的任务可以实现高效的RL优化，而主观任务仍然具有挑战性。&lt;/p&gt;
&lt;h3 id=&#34;rule-based-rewards&#34;&gt;Rule-based Rewards
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Accuracy rewards:对于具有确定性结果的任务（例如数学），策略必须在规定的分隔符（通常为\boxed{…}）内产生最终解决方案。然后，自动检查器将此输出与地面实况进行比较。对于编码任务，单元测试或编译器提供通过/失败信号&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Format rewards:这些奖励施加了一个结构约束，要求模型将其私有思想链放置在&lt;think&gt;和&lt;/inthink&gt;之间，并在单独的字段中输出最终答案（例如&lt;answer&gt;…&lt;/answer&gt;）。这提高了大规模RL中的可靠解析和验证&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rule-based-verifier&#34;&gt;Rule-based Verifier
&lt;/h3&gt;&lt;p&gt;基于规则的奖励通常来自基于规则的验证器。这些依赖于大量手动编写的等价规则来确定预测的答案是否与基本事实相匹配。目前，广泛使用的数学验证器主要基于Python库Math-Verify1和SymPy2构建。此外，一些作品，如DAPO[2025d]和DeepScaleR[2025c]，也提供了开源和成熟的验证器。最近，Huang等人[2025e]强调了与基于规则和基于模型的验证器相关的独特局限性，为设计更可靠的奖励系统提供了信息。&lt;/p&gt;
&lt;h4 id=&#34;训练人工智能系统执行任务的难易程度与任务的可验证程度成正比&#34;&gt;训练人工智能系统执行任务的难易程度与任务的可验证程度成正比
&lt;/h4&gt;&lt;h3 id=&#34;generative-rewards&#34;&gt;Generative Rewards
&lt;/h3&gt;&lt;h4 id=&#34;这里着重说明-generative-rewards-for-non-verifiable-tasks&#34;&gt;这里着重说明 Generative Rewards for Non-Verifiable Tasks
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reasoning Reward Models (Learning to Think)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rubric-based Rewards (Structuring Subjectivity)：强调细粒度奖励&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Co-Evolving Systems (Unifying Policy and Reward):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Self-Rewarding：自我奖励，一个模型既充当policy model，也充当reward model&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Co-Optimization：policy和reward模型共同训练&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dense-rewards&#34;&gt;Dense Rewards
&lt;/h3&gt;&lt;p&gt;dense rewards 和 verifiers对于open-domain还是太难了&lt;/p&gt;
&lt;p&gt;Scaling remains challenging for tasks like open-domain text generation due to the difficulty of defining dense rewards or using verifiers.&lt;/p&gt;
&lt;p&gt;Granularity细粒度分为：Trajectory（整个序列），Token，Step，Turn（Agent）&lt;br&gt;
这几个信号可以相互转换，比如把globa returns 转换成 localized signals，奖励的重新分配&lt;br&gt;
可以理解为从每次交互中直接分配和从结果中分解得出的回合级别奖励&lt;/p&gt;
&lt;h3 id=&#34;unsupervised-rewards&#34;&gt;Unsupervised Rewards
&lt;/h3&gt;&lt;p&gt;cluster：聚类（也有集群的意思）&lt;/p&gt;
&lt;p&gt;majority vote：多数投票&lt;/p&gt;
&lt;p&gt;Heuristic Rewards（启发式奖励）：这种方法构成了另一种基于规则的奖励形式，采用基于输出属性（如长度或格式）的简单预定义规则作为质量的代理。由DeepSeek-R1开创。不会提高模型真正能力？（质疑）&lt;/p&gt;
&lt;h3 id=&#34;rewards-shaping&#34;&gt;Rewards Shaping
&lt;/h3&gt;&lt;p&gt;Rewards Shaping将稀疏信号丰富为稳定的、信息丰富的梯度，用于LLM训练&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Rule-based Reward Shaping&lt;br&gt;
最简单的：把rule-based verifier和reward model组合起来生成overall reward signal。通常有一个constant coefficient平衡the contributions of the reward model and the rule-based component，不是所有正确的responses都是同样的scores，这样可以把所有的responses重新排序，避免无效的学习梯度&lt;/p&gt;
&lt;p&gt;这种启发式组合策略在开放域任务中得到了广泛的应用，提供了更多的信息和有效的奖励信号。&lt;/p&gt;
&lt;p&gt;另一种方法是DeepSeek-R1中实现结果级奖励和格式奖励，能让LLM学习长思维链推理，用于解决LLM输出中的各种异常。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Structure-based Reward Shaping
Pass@k在推导和分析优势和有效近似值时，将集合级目标分解回单个样本信用分配。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;policy-optimization&#34;&gt;Policy Optimization
&lt;/h3&gt;&lt;p&gt;最近的研究把on-policy RL和offline datasets结合在一起来进行optimization同时使用各种regularization techniques（正则化技术）比如entropy和KL防止overfitting&lt;/p&gt;
&lt;h4 id=&#34;environmentthe-context-in-rl-for-llms&#34;&gt;environment:the context in RL for LLMs
&lt;/h4&gt;&lt;h4 id=&#34;policythe-distribution-of-the-next-level-prediction&#34;&gt;policy:the distribution of the next-level prediction
&lt;/h4&gt;&lt;h4 id=&#34;由于llm中的大量参数llm的rl策略优化算法大多是基于一阶梯度的算法&#34;&gt;由于LLM中的大量参数，LLM的RL策略优化算法大多是基于一阶梯度的算法
&lt;/h4&gt;&lt;h3 id=&#34;notations符号&#34;&gt;Notations（符号）
&lt;/h3&gt;&lt;h4 id=&#34;当前状态s的预期积累奖励表示为vvalue函数&#34;&gt;当前状态s的预期积累奖励表示为V（value）函数
&lt;/h4&gt;&lt;h4 id=&#34;当前状态动作对应的预期积累表示为qquality函数&#34;&gt;当前状态动作对应的预期积累表示为Q（quality）函数
&lt;/h4&gt;&lt;h4 id=&#34;优势函数as-a--qs-a--v-s该优势衡量的是与现有政策相比当前行动在预期总回报方面有多大改进&#34;&gt;优势函数：A(s, a) = Q(s, a) − V (s).该优势衡量的是与现有政策相比，当前行动在预期总回报方面有多大改进。
&lt;/h4&gt;&lt;h3 id=&#34;优化算法的历程&#34;&gt;优化算法的历程
&lt;/h3&gt;&lt;p&gt;PPO算法[Schulman等人，2017b]首次被提出作为TRPO算法[Schurman等人，2015a]的计算高效近似。&lt;br&gt;
&lt;img src=&#34;http://localhost:1313/p/lrm-rl-survey/algorithm.jpg&#34;
	width=&#34;1161&#34;
	height=&#34;795&#34;
	srcset=&#34;http://localhost:1313/p/lrm-rl-survey/algorithm_hu_ab70d2da1d0a05a6.jpg 480w, http://localhost:1313/p/lrm-rl-survey/algorithm_hu_bddcdd47c9c7c11e.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;algorithm&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;350px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;critic-based-algorithms&#34;&gt;Critic-based Algorithms
&lt;/h3&gt;&lt;p&gt;critic需要和LLM一起run和update，这样会导致巨大的计算开销，而且对于复杂的任务来说，扩展性不好&lt;/p&gt;
&lt;h3 id=&#34;critic-free-algorithms&#34;&gt;Critic-Free Algorithms
&lt;/h3&gt;&lt;p&gt;只需要sequence-level rewards for training&lt;/p&gt;
&lt;p&gt;对于RLVR任务可以防止reward hacking等问题，这使得Critic-Free Algorithms更具有可扩展性&lt;/p&gt;
&lt;p&gt;最近的研究表明response-level足以用于RL的可扩展推理任务&lt;/p&gt;
&lt;p&gt;最受欢迎的critic-free approach是GRPO，新推出的GSPO[Zheng等人，2025a]，用序列级剪切代替了逐符号剪切的重要性采样率&lt;/p&gt;
&lt;p&gt;SPO引入了一种无组、单流策略优化，用持久的KL自适应值跟踪器和全局优势归一化来替换每组基线，从而产生比GRPO更平滑的收敛和更高的精度&lt;/p&gt;
&lt;h4 id=&#34;importance-sampling-for-policy-optimization&#34;&gt;Importance Sampling for Policy Optimization
&lt;/h4&gt;&lt;p&gt;TRPO引入了RL中重要性抽样的第一个版本，其中在目标中引入了令牌式重要性比wi，t&lt;br&gt;
这种方法在最近的工作中被广泛采用，如GRPO。由于无法在CoT的长上下文中有效计算实际分布比率，因此这种方法仅限于token-level重要性比率&lt;/p&gt;
&lt;p&gt;token-level重要性采样在RL算法中引入了另一种偏差，因为实际采样分布给定的策略是针对状态-动作对定义的，而token-level方法只考虑当前动作。GMPO[赵等人，2025f]通过引入几何平均来寻求缓解，以提高具有极端重要性采样率的token的训练鲁棒性&lt;/p&gt;
&lt;p&gt;在GSPO的最新工作中[Zheng等人，2025a]，计算了序列级重要性抽样因子。GSPO添加了一个唯一的归一化因子，以确保可以计算概率比，但这种方法也是对实际重要性抽样因子的有偏估计&lt;/p&gt;
&lt;h3 id=&#34;off-policy-optimization&#34;&gt;Off-policy Optimization
&lt;/h3&gt;&lt;p&gt;Off-policy RL通过把data collection 和 policy learning解耦，实现了从历史、异步或离线数据集进行训练，从而提高了样本效率&lt;/p&gt;
&lt;p&gt;选择性地replay 早期的推理traces可以提高exploration for LLM reasoning&lt;/p&gt;
&lt;p&gt;现在很多都在对数据进行处理来提升exploration&lt;/p&gt;
&lt;h3 id=&#34;regularization-objectives&#34;&gt;Regularization Objectives
&lt;/h3&gt;&lt;p&gt;Objective-specific regularization helps balance explration and exploitation,boosting RL effiency and policy performance.&lt;/p&gt;
&lt;p&gt;KL,entropy and length regularization remain open questions,each affects policy optimization and scalability&lt;/p&gt;
&lt;p&gt;Length Penalty建议应用基于问题难度的自适应长度惩罚来保持模型的能力&lt;/p&gt;
&lt;h3 id=&#34;sampling-hyper-parameters&#34;&gt;Sampling Hyper-parameters
&lt;/h3&gt;&lt;h4 id=&#34;exploration-and-exploitation-dynamics&#34;&gt;Exploration and Exploitation Dynamics
&lt;/h4&gt;&lt;p&gt;一些工作提出了一种动态方法，例如分阶段提高温度(e.g., 1.40 → 1.45 → 1.50 for a 4B model, 0.7 → 1.0 → 1.1 for a 7B model)&lt;/p&gt;
&lt;p&gt;entropy 在0.3被发现是最佳平衡&lt;/p&gt;
&lt;p&gt;其他的工作只是倡导提高一个固定的温度（例如1.0或1.2）来鼓励初步探索，同时指出它本身不足以防止长期的熵下降&lt;/p&gt;
&lt;h4 id=&#34;length-budgeting-and-sequence-management&#34;&gt;Length Budgeting and Sequence Management
&lt;/h4&gt;&lt;p&gt;几乎所有的work都在努力管理生成响应的长度，以平衡性能和成本。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This involves starting RL with a short context window (e.g., 8k) before progressively increasing it to 16k, 24k, or 32k in later stages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;初始的短上下文阶段被认为是必不可少的，因为它迫使模型学习更简洁、更具令牌效率的推理模式&lt;/p&gt;
&lt;h2 id=&#34;foundational-problems&#34;&gt;Foundational Problems
&lt;/h2&gt;&lt;h3 id=&#34;rls-role-sharpening-or-discovery&#34;&gt;RL’s Role: Sharpening or Discovery
&lt;/h3&gt;&lt;h3 id=&#34;rl-vs-sft-generalize-or-memorize&#34;&gt;RL vs. SFT: Generalize or Memorize
&lt;/h3&gt;&lt;p&gt;发现RL擅长巩固和增强现有能力，而SFT在引入新知识或新模型能力方面更有效&lt;/p&gt;
&lt;h3 id=&#34;model-prior-weak-and-strong&#34;&gt;Model Prior: Weak and Strong
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;R1-Zero：直接将大规模基于规则的RL应用于基本模型，产生新兴的长期推理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;R1：包含冷启动&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基础模型先验比指导模型更适合强化学习，通常会产生比从高度一致的指导模型开始时观察到的更平滑的改进轨迹，其中根深蒂固的格式和服从先验可能会干扰奖励的形成&lt;/p&gt;
&lt;h4 id=&#34;model-family-differences&#34;&gt;Model Family Differences
&lt;/h4&gt;&lt;h3 id=&#34;reward-type-process-or-outcome&#34;&gt;Reward Type: Process or Outcome
&lt;/h3&gt;&lt;h2 id=&#34;training-resources&#34;&gt;Training Resources
&lt;/h2&gt;&lt;h3 id=&#34;static-corpus&#34;&gt;Static Corpus
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Math&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;STEM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Agent&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mixture&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rl-infrastructure--framework&#34;&gt;RL Infrastructure &amp;amp; Framework
&lt;/h3&gt;&lt;p&gt;e.g.OpenRLHF/veRL/AReaL/slime/TRL&lt;/p&gt;
&lt;h3 id=&#34;dynamic-environment&#34;&gt;Dynamic Environment
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Rule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Game&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ensemble&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;applications&#34;&gt;Applications
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1.Agentic Tasks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2.Coding Tasks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3.Multimodal Tasks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4.Robotics Tasks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5.Multi-Agent Systems&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;6.Medical Tasks&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Pass@k论文复现</title>
        <link>http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</link>
        <pubDate>Sun, 21 Sep 2025 16:00:00 +0800</pubDate>
        
        <guid>http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</guid>
        <description>&lt;img src="http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/ByteDance.jpg" alt="Featured image of post Pass@k论文复现" /&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/Seed.jpg&#34;
	width=&#34;400&#34;
	height=&#34;400&#34;
	srcset=&#34;http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/Seed_hu_2d5c39b72441c640.jpg 480w, http://localhost:1313/p/pass@k%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/Seed_hu_e08f665f0403ee6b.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;passk-training-for-adptively-balancing-eplortion-and-exploitation-of-lrms&#34;&gt;Pass@k Training for Adptively Balancing Eplortion and Exploitation of LRMs
&lt;/h1&gt;&lt;h2 id=&#34;passk论文解读&#34;&gt;Pass@k论文解读
&lt;/h2&gt;&lt;p&gt;policy探索能力的指标：the natural prevention of the decrease in the entropy of policy distribution&lt;/p&gt;
&lt;p&gt;Pass@1和Pass@k之间的主要区别在于奖励计算和优势估计过程。&lt;/p&gt;
&lt;p&gt;vanilla：原来的&lt;br&gt;
Ground Truth是正确答案（标准答案）&lt;/p&gt;
&lt;h4 id=&#34;探索能力&#34;&gt;探索能力:
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the entropy of policy distribution处在一个较高的水平&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the answer diversity of the negative response处在一个较高的水平&lt;br&gt;
Pass@k的entropy在RLVR procedure的200step左右开始上升&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;k值影响passk训练&#34;&gt;k值影响Pass@k训练
&lt;/h3&gt;&lt;p&gt;实验中从4，8，16中调整k值&lt;/p&gt;
&lt;p&gt;无论k的值是多少，随着训练的进行，训练奖励都可以提高到相对较高的水平，这表明k的值不是帮助LLMs逃脱局部最优解的关键性因素&lt;/p&gt;
&lt;h4 id=&#34;k值越大训练效率越慢k值越大优势值越小导致优化步骤越短训练效率越低&#34;&gt;k值越大，训练效率越慢（k值越大，优势值越小，导致优化步骤越短，训练效率越低）
&lt;/h4&gt;&lt;h3 id=&#34;训练效率的影响因素&#34;&gt;训练效率的影响因素
&lt;/h3&gt;&lt;p&gt;实验在N = 32 和 k = 8的设置下使用{1 x 10-6,2 x 10-6,4 x 10-6}learning rate&lt;/p&gt;
&lt;h4 id=&#34;随着学习率的提高拐点出现得更早表明训练效率更高&#34;&gt;随着学习率的提高，拐点出现得更早，表明训练效率更高
&lt;/h4&gt;&lt;h4 id=&#34;最大优势值不是帮助模型表现优异的关键性因素&#34;&gt;最大优势值不是帮助模型表现优异的关键性因素
&lt;/h4&gt;&lt;h4 id=&#34;为更难的问题分配更大的优化强度可以有效地提高训练效率&#34;&gt;为更难的问题分配更大的优化强度可以有效地提高训练效率
&lt;/h4&gt;&lt;p&gt;根据the entropy of policy distribution的高低，区分high-exploration和low-exploration。&lt;/p&gt;
&lt;p&gt;high-exploration使用Pass@1 advantage fuction来exploit prior exploration，low-exploration使用Pass@k advantage function来encourage further exploration。&lt;/p&gt;
&lt;h4 id=&#34;implicit-reward-design隐式奖励设计可以控制优化过程&#34;&gt;Implicit reward design（隐式奖励设计）可以控制优化过程
&lt;/h4&gt;&lt;p&gt;具体地说，结合或动态调整不同形式的优势估计，可以同时提高exploration and exploitation能力&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;passk论文复现&#34;&gt;Pass@k论文复现
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2508.10751&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;arxiv文章&lt;/a&gt;👈&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/RUCAIBox/Passk_Training&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;github仓库&lt;/a&gt;👈&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/datasets/RUC-AIBOX/Passk_Training_Maze&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Datasets&lt;/a&gt;👈&lt;/p&gt;
&lt;h3 id=&#34;maze&#34;&gt;Maze
&lt;/h3&gt;&lt;p&gt;每个迷宫由文本表示，包含n行和n列，总共n∗n个字符&lt;/p&gt;
&lt;p&gt;四个字符“S”、“E”、“.”和“*”中的一个，分别表示起点、目的地、可用地点和不可用地点&lt;/p&gt;
&lt;p&gt;给定迷宫，LLM可以首先生成思维或推理过程，然后生成最终答案，其中包括四个动作“U”、“D”、“L”和“R”中的一个，分别表示向上、向下、向左和向右移动&lt;/p&gt;
&lt;p&gt;对于训练数据，我们构建了大小为9×9、11×11、13×13和15×15的迷宫，以增加训练数据的多样性&lt;/p&gt;
&lt;p&gt;对于测试数据，为了评估RLVR过程的泛化能力，我们不仅使用训练数据集进行相同大小的迷宫，还收集了大小为7×7、17×17、19×19和21×21的迷宫&lt;/p&gt;
&lt;p&gt;为了确保实验的有效性，我们在生成训练和测试数据后进行了严格的重复数据删除操作&lt;/p&gt;
&lt;p&gt;Training Set 都是10,000;Test Set除了7 * 7,剩下的都是100&lt;/p&gt;
&lt;h3 id=&#34;implementation-details&#34;&gt;Implementation Details
&lt;/h3&gt;&lt;h4 id=&#34;training&#34;&gt;Training
&lt;/h4&gt;&lt;p&gt;backbone model:Qwen2.5-7B-Instruct和Qwen2.5-32B Instruct&lt;/p&gt;
&lt;p&gt;DAPO&lt;/p&gt;
&lt;p&gt;εlow=0.2和εhigh=0.28&lt;/p&gt;
&lt;p&gt;token-level policy gradient loss&lt;/p&gt;
&lt;p&gt;remove other optimizations&lt;/p&gt;
&lt;p&gt;learning rate:1 × 10−6&lt;/p&gt;
&lt;p&gt;warmup:10&lt;/p&gt;
&lt;p&gt;prompt batch size(BS prompt):128&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt Batch Size：是模型推理生成的粒度。它决定在一次性并行处理多少个独立的提示词（例如，多少个用户问题），并同时为它们生成文本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;mini-batch size(BS mini):32&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mini-batch Size：是模型权重更新的粒度。它决定在计算一次梯度下降时，使用多少条训练数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;rollout times:32&lt;/p&gt;
&lt;p&gt;positive reward Rpos = 1&lt;/p&gt;
&lt;p&gt;negative reward Rneg = 0&lt;/p&gt;
&lt;p&gt;do not employ any regularization methods, such as KL or Entropy regularization&lt;br&gt;
temperature:1.0&lt;/p&gt;
&lt;p&gt;Top_P:0.95&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从概率最高的词开始累加它们的概率，直到累积概率达到或刚刚超过你设定的 top_p 值&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each question,we sample 32responses for Maze task and sample 8 responses for other tasks&lt;/p&gt;
&lt;h3 id=&#34;versionsdependencies&#34;&gt;Versions/Dependencies
&lt;/h3&gt;&lt;p&gt;Python 3.10.18&lt;br&gt;
Ray 2.49.1&lt;br&gt;
grpcio 1.75.0&lt;br&gt;
Ubuntu 24.04.2 LTS&lt;/p&gt;
&lt;h3 id=&#34;如何从huggingface上下载数据集和模型&#34;&gt;如何从huggingface上下载数据集和模型
&lt;/h3&gt;&lt;p&gt;从huggingface上下载文件有2种方式，一种是直接登录后在网页上下载；一种是通过huggingface-cli命令下载。&lt;/p&gt;
&lt;p&gt;本文介绍的是第二种下载方式。&lt;/p&gt;
&lt;h3 id=&#34;安装&#34;&gt;安装
&lt;/h3&gt;&lt;p&gt;对于huggingface-cli命令的下载直接通过pip命令安装即可：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;pip install -U huggingface_hub[hub_transfer]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;对于国内用户还可以通过设置镜像网站的方式加速下载：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;#linux
export HF_ENDPOINT=https://hf-mirror.com&lt;br&gt;
#windows&lt;br&gt;
set HF_ENDPOINT=https://hf-mirror.com&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;使用命令行下载&lt;/p&gt;
&lt;h4 id=&#34;模型&#34;&gt;模型
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;huggingface-cli download &amp;ndash;resume-download [1] &amp;ndash;local-dir [2] &amp;ndash;local-dir-use-symlinks False&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;数据集&#34;&gt;数据集
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;huggingface-cli download &amp;ndash;repo-type dataset &amp;ndash;resume-download [3] &amp;ndash;local-dir [4] &amp;ndash;local-dir-use-symlinks False &amp;ndash;token hf_***&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;格式为：[1]和[3]表示项目的路径，格式为用户名/项目，比如mistralai/Mistral-7B-Instruct-v0.2表示的是mistralai下的7B instruct v0.2权重。[2]和[4]表示的是本地的保存地址。&lt;/p&gt;
&lt;p&gt;需要的注意的是有些仓库需要登录才可以下载，形如–token hf_***为huggingface的token配置。token的生成需要在huggingface个人页面生成.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ray.init()初始化挂起/失败问题的解决</title>
        <link>http://localhost:1313/p/ray.init%E5%88%9D%E5%A7%8B%E5%8C%96%E6%8C%82%E8%B5%B7/%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3/</link>
        <pubDate>Sat, 20 Sep 2025 10:00:00 +0800</pubDate>
        
        <guid>http://localhost:1313/p/ray.init%E5%88%9D%E5%A7%8B%E5%8C%96%E6%8C%82%E8%B5%B7/%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3/</guid>
        <description>&lt;img src="http://localhost:1313/p/ray.init%E5%88%9D%E5%A7%8B%E5%8C%96%E6%8C%82%E8%B5%B7/%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3/Ray.jpg" alt="Featured image of post ray.init()初始化挂起/失败问题的解决" /&gt;&lt;h2 id=&#34;abstract&#34;&gt;Abstract
&lt;/h2&gt;&lt;p&gt;此文章发布约一周前就已经发现该问题了，但是由于专注看官方文档和仓库进行规范 + 课内事情，一直没有得到解决。&lt;/p&gt;
&lt;p&gt;在发文前一天发现此问题需要重点解决（无法避免），询问了师兄（论文作者）并咨询了相关团队，未果，所以花了两整天才解决这一个bug。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;issue&#34;&gt;Issue
&lt;/h2&gt;&lt;h3 id=&#34;what-happened--what-you-expected-to-happen&#34;&gt;What happened + What you expected to happen
&lt;/h3&gt;&lt;p&gt;Running the following snippet will hang indefinitely&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import  ray
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt;&amp;gt;&amp;gt; ray.init()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2025-09-20 11:44:47,741 INFO worker.py:1538 -- Started a local Ray instance.  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Sometimes it will fail instead&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[2025-09-20 11:50:22,050 E 31652 31652] core_worker.cc:179: Failed to register worker 01000000ffffffffffffffffffffffffffffffffffffffffffffffff to Raylet. IOError: [RayletClient] Unable to register worker with raylet. No such file or directory
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;versionsdependencies&#34;&gt;Versions/Dependencies
&lt;/h3&gt;&lt;p&gt;Python 3.10.18&lt;br&gt;
Ray 2.49.1&lt;br&gt;
grpcio 1.75.0&lt;br&gt;
Ubuntu 24.04.2 LTS&lt;/p&gt;
&lt;h3 id=&#34;reproduction-script&#34;&gt;Reproduction script
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;import ray
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ray.init()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;issue-severity&#34;&gt;Issue Severity
&lt;/h3&gt;&lt;p&gt;High: It blocks me from completing my task.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;上面全英是因为当时要提issue或者给Ray框架作者发邮件，但是后来解决了，就打算留下来了，这样后来的人可以模仿一下这个写法。&lt;/p&gt;
&lt;h2 id=&#34;可能的问题&#34;&gt;可能的问题
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;1.workers实际上并没有启动。（可以看一下&lt;code&gt;/tmp/ray/session_latest/raylet.out&lt;/code&gt;,如果在&lt;code&gt;/tmp/ray/session_latest/&lt;/code&gt;看到有前缀&lt;code&gt;python-core-worker-&lt;/code&gt; 的可以看一下，因为这个能了解工作进程可能发生了什么）&lt;/li&gt;
&lt;li&gt;2.系统中进程数/线程数设置错误（可以通过cat /proc/sys/kernel/threads-max查看系统中一个进程可以创建多少个线程）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;可能的方法&#34;&gt;可能的方法
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;1.在&lt;code&gt;import ray&lt;/code&gt;之后加上&lt;code&gt;ray.init(num_cpus=56, num_gpus=2)&lt;/code&gt;。具体参数需要根据服务器进行自定义。
作者根据这个方法对自己进行了适配解决了问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;具体操作yhyverltrainerconfigppo_traineryaml配置文件中对num_cpus0修改成num_cpus10-num_gpus1进行定义&#34;&gt;具体操作：&lt;code&gt;/yhy/verl/trainer/config/ppo_trainer.yaml&lt;/code&gt;配置文件中对&lt;code&gt;num_cpus=0&lt;/code&gt;修改成&lt;code&gt;num_cpus=10&lt;/code&gt;, &lt;code&gt;num_gpus=1&lt;/code&gt;进行定义。
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;2.升级&lt;code&gt;grpcio&lt;/code&gt;,2023年的时候安装&lt;code&gt;grpcio 1.48.1&lt;/code&gt; 版本是有用的,相应的&lt;code&gt;venv&lt;/code&gt;是 &lt;code&gt;CentOS 7,Python 3.7.11，Ray 2.5.1,grpcio1.48.1&lt;/code&gt;。&lt;br&gt;
但我进行升级的时候，无法解决该问题，并且会导致包之间的冲突。（是一个opencv的包，已经&lt;code&gt;pip install&lt;/code&gt;了）&lt;/li&gt;
&lt;li&gt;3.添加&lt;code&gt;ulimit -n 65536&lt;/code&gt;语句，因为分布式训练一开始可能会开成千上万个进程，默认是4096，所以会导致线程创建失败。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;感觉这点也是有用的但可能不是主要因素&#34;&gt;感觉这点也是有用的，但可能不是主要因素？
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;4.一定要设置参数,只是用&lt;code&gt;ray.init()&lt;/code&gt;就会崩溃。需要手动设置&lt;code&gt;num_cpus&lt;/code&gt;。&lt;br&gt;
这点和1重复了，可以说是大家实验得到的结论？（也许）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;近期其他人也遇到过该问题&#34;&gt;近期其他人也遇到过该问题
&lt;/h2&gt;&lt;p&gt;2024.1.16也有在&lt;code&gt;Ubuntu 20.04&lt;/code&gt;上遇到同样的问题 &lt;code&gt;venv: ray == 2.7.1,grpcio == 1.59.2,python == 3.11.5&lt;/code&gt;&lt;br&gt;
2024.4.2有在&lt;code&gt;ubuntu 22.04.3&lt;/code&gt;（docker内部）上遇到同样的问题，但是他只是失败，而不是挂起。在docker之外运行良好（他的M1 MacBook上）&lt;/p&gt;
&lt;p&gt;2024.4.14，2024.4.17，2024.7.11等等太多人遇到同样的问题了&lt;/p&gt;
&lt;h2 id=&#34;至此问题的解决方案已经讲述完毕&#34;&gt;至此，问题的解决方案已经讲述完毕。
&lt;/h2&gt;&lt;hr&gt;
&lt;h3 id=&#34;回顾解决问题的流程&#34;&gt;回顾解决问题的流程
&lt;/h3&gt;&lt;p&gt;刚遇到这个问题，我先看了一下是不是自己遇到过的，发现没有就交给了copilot，发现copilot无法解决，给了chatgpt5，同样无法解决，又给了Gemini看看能不能有些新意（其实这步可以忽略），上述方法都不行，问了师兄是否遇到过。&lt;/p&gt;
&lt;p&gt;发现他们都没有遇到过，我只能去Ray官方仓库里面的issue进行查看。感觉现在人们都不怎么用StackOverflow等等论坛了，所以就只能去issue里面找了。&lt;/p&gt;
&lt;p&gt;幸运的是发现了很多人遇到了同样的问题和报错，我就开始追根溯源，发现从17.18年就有人提出了这个问题，当时也有相应的解决办法，但是随着版本更新变得不适用。&lt;br&gt;
我就开始收集所有对这个问题的理解和解决方案，逐个尝试，很幸运的是我debug成功了！&lt;/p&gt;
&lt;p&gt;因为论文中没有常见的问题的解决方案，如果有的话应该是第一步先去看的。&lt;/p&gt;
&lt;p&gt;这就是我整个解决这个问题的流程，大体上看似乎没有太大问题。但是还是可以优化一下，下次遇到类似比较“偏”的问题可以更快，心态更平和地解决这个问题。&lt;/p&gt;
&lt;h3 id=&#34;看到这里了祝你遇到像我遇到的这样比较偏门的问题时也可以顺利并更快地解决&#34;&gt;看到这里了，祝你遇到像我遇到的这样比较“偏门”的问题时，也可以顺利并更快地解决！
&lt;/h3&gt;</description>
        </item>
        <item>
        <title>RUC-research-intern</title>
        <link>http://localhost:1313/p/ruc-study-framework/</link>
        <pubDate>Tue, 16 Sep 2025 10:00:00 +0800</pubDate>
        
        <guid>http://localhost:1313/p/ruc-study-framework/</guid>
        <description>&lt;img src="http://localhost:1313/p/ruc-study-framework/RUC.jpg" alt="Featured image of post RUC-research-intern" /&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/ruc-study-framework/AI-Box.jpg&#34;
	width=&#34;200&#34;
	height=&#34;200&#34;
	srcset=&#34;http://localhost:1313/p/ruc-study-framework/AI-Box_hu_dd5bef9123c22f74.jpg 480w, http://localhost:1313/p/ruc-study-framework/AI-Box_hu_3cf40d827e974d65.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI Box小组&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;科研日记&#34;&gt;科研日记
&lt;/h1&gt;&lt;p&gt;用来记录我远程实习的日子&lt;/p&gt;
&lt;h4 id=&#34;20250716&#34;&gt;2025.07.16
&lt;/h4&gt;&lt;p&gt;成为赵老师的本科实习生，暑假跟着师兄做了一个横向&lt;/p&gt;
&lt;h5 id=&#34;家里网好差本来服务器就慢还是要在学校多用功&#34;&gt;家里网好差（本来服务器就慢），还是要在学校多用功
&lt;/h5&gt;&lt;p&gt;暑假一共6周，还有各种事情，加上休息吃饭探亲balabala也做不了太多事情。确定了方向，看了一些知乎上的论文解读（后面发现如果要通透还是要看原文）。&lt;/p&gt;
&lt;h4 id=&#34;20250916&#34;&gt;2025.09.16
&lt;/h4&gt;&lt;p&gt;近期在搞论文复现的实验，跟上课题组的进度&lt;/p&gt;
&lt;p&gt;今天在修改run_dapo.sh脚本的时候发现了几个常见的问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;.sh的格式十分严格&lt;/li&gt;
&lt;li&gt;Parquet文件格式&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/680143641&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Parquet文件格式讲解&lt;/a&gt;👈&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;vibe coding脚本是无比正确的。&lt;br&gt;
不知不觉已经两个月了，但对我而言收获是颇多的。&lt;/p&gt;
&lt;h5 id=&#34;选择一个好组是十分重要的软院tic高瓴ai-box让我深刻感受到了好的氛围成套的培养体系&#34;&gt;选择一个好组是十分重要的！软院TIC，高瓴AI BOX让我深刻感受到了好的氛围，成套的培养体系！
&lt;/h5&gt;&lt;h5 id=&#34;希望自己可以平衡好课内科研还有生活等等其他方面&#34;&gt;希望自己可以平衡好课内＋科研，还有生活等等其他方面
&lt;/h5&gt;&lt;p&gt;晚上睡前简单看了一下verl官方文档里面Config Explanation的Data部分&lt;/p&gt;
&lt;h5 id=&#34;梯度下降的三种常见形式&#34;&gt;梯度下降的三种常见形式
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;1.Batch Gradient Descent（批量梯度下降）&lt;/li&gt;
&lt;li&gt;2.Stochastic Gradient Descent (SGD，随机梯度下降)&lt;/li&gt;
&lt;li&gt;3.Mini-batch Gradient Descent（小批量梯度下降）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;几个epoch就是过几次数据集，实践中把 “batch” 这个词用得比较宽：在框架/代码里 batch_size 常指 mini-batch 的大小，所以容易混淆 “batch gradient descent” 与 “mini-batch”。&lt;/p&gt;
&lt;h5 id=&#34;prompt_key&#34;&gt;prompt_key
&lt;/h5&gt;&lt;p&gt;这个不是学术上固定的术语，而是很多框架（比如 HuggingFace、VERL、LangChain 等）里常见的实现细节。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 字典 / JSON / 配置文件 里，用来标记某个 prompt 的 键名（key）。&lt;/li&gt;
&lt;li&gt;这样做可以在代码里快速查找/复用不同的 prompt 模板。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;prompts = {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;translation&amp;#34;: &amp;#34;Translate the following English text into Chinese: {text}&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;summarization&amp;#34;: &amp;#34;Summarize the following paragraph: {text}&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;qa&amp;#34;: &amp;#34;Answer the question based on the context: {context}\nQuestion: {question}&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这里 &amp;ldquo;translation&amp;rdquo;, &amp;ldquo;summarization&amp;rdquo;, &amp;ldquo;qa&amp;rdquo; 就是 prompt_key，
而它们对应的 value 就是具体的 prompt 模板。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prompt = 给模型的输入提示，引导它完成任务。&lt;br&gt;
Prompt_key = 在程序里标记或索引 prompt 模板的“名字/键”，方便管理和调用。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;RM（Reward Model，奖励模型）：在 RLHF 里给生成结果打分的模型。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;如果使用基于模型的 RM，并且策略和 RM 的聊天模板不同，则需要设置data.return_raw_input_ids=True
data.return_full_prompt=True
用户输入：你好，介绍一下强化学习
返回：[INST] 你好，介绍一下强化学习 [/INST]
data.return_raw_chat=True
用户输入：你好，介绍一下强化学习
返回的就是:你好，介绍一下强化学习&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;20250917&#34;&gt;2025.09.17
&lt;/h4&gt;&lt;p&gt;早晨起来去工位继续看verl&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;actor_rollout_ref.hybrid_engine：是否是混合引擎，目前只支持混合引擎.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Dropout 是一种 正则化方法，用来防止神经网络过拟合。在训练时，随机“丢弃”一部分神经元（让它们暂时不参与计算和更新）。推理时,不再丢弃任何神经元，只是使用完整的输出。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;actor_rollout_ref.model.use_remove_padding一般都选true移除&lt;code&gt;&amp;lt;PAD&amp;gt;&lt;/code&gt;来加速推理，但是多模态或者大工程里仍有人使用false&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Temperature （温度）。T = 1 → 正常分布。T &amp;gt; 1 → 分布更平滑，增加随机性，容易生成多样化甚至跑偏的内容。T &amp;lt; 1 → 分布更尖锐，模型更确定（更倾向选概率最高的 token，输出保守）。&lt;br&gt;
Top-k：从 softmax 排序后的前 k 个 token 中随机抽样。&lt;br&gt;
Top-p：动态选择前 累计概率 ≥ p 的最小 token 集合，从里面采样。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Actor:负责 更新参数&lt;br&gt;
Ref (Reference Model):负责 对比/约束。它是冻结的（不更新），通常是最初的预训练模型。&lt;br&gt;
Rollout:负责 产生输出（推理采样）&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;EOS = End Of Sequence（序列结束标记）。在 tokenizer 里，EOS 往往是个特殊的 &lt;code&gt;&amp;lt;/s&amp;gt;&lt;/code&gt; 或 &lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt; 符号。ignore_eos=True 在训练中一般少用，除非你需要 生成固定长度序列，或者想收集超过 EOS 的 rollouts 数据。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;20250919&#34;&gt;2025.09.19
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;一个深度学习训练任务中，nodes 指的是计算机，而 gpus-per-node 指的是每台计算机上安装的 GPU 数量。&lt;br&gt;
可以把 nodes 理解为一台台服务器，每台服务器里可以插上多张显卡（GPU）。&lt;br&gt;
nnodes: 1：你正在使用一台计算机来运行任务。&lt;br&gt;
n_gpus_per_node: 8：这台计算机上插了 8 张 GPU。&lt;br&gt;
所以，这个配置的意思是，你用一台装有 8 张 GPU 的服务器来运行你的任务。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;verl官方文档看完了，嗯。。还是要去看仓库&lt;/p&gt;
&lt;p&gt;都在赶iclr导致服务器又变得卡卡的&lt;/p&gt;
&lt;p&gt;实验复现遇到了问题导致一直是卡住的状态&lt;/p&gt;
&lt;p&gt;神器：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;pkill -9 -u $USER -f ray&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;20250920&#34;&gt;2025.09.20
&lt;/h4&gt;&lt;p&gt;ray官方仓库，试图解决Ray实例后ray.init()挂起/失败问题&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;import  ray
ray.init()
2025-09-20 11:44:47,741 INFO worker.py:1538 &amp;ndash; Started a local Ray instance.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;有时候会卡住&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python
import  ray
ray.init()
2025-09-20 11:44:47,741 INFO worker.py:1538 &amp;ndash; Started a local Ray instance.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;有时候会失败&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[2025-09-20 11:50:22,050 E 31652 31652] core_worker.cc:179: Failed to register worker 01000000ffffffffffffffffffffffffffffffffffffffffffffffff to Raylet. IOError: [RayletClient] Unable to register worker with raylet. No such file or directory&lt;/p&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;versionsdependencies&#34;&gt;Versions/Dependencies
&lt;/h5&gt;&lt;p&gt;Python 3.10
Ray
grpcio
OS:&lt;/p&gt;
&lt;h5 id=&#34;reproduction-script&#34;&gt;Reproduction script
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;import ray
ray.init()&lt;/p&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;issue-severity&#34;&gt;Issue Severity
&lt;/h5&gt;&lt;p&gt;High:It blocks me from completing my task.&lt;/p&gt;
&lt;p&gt;可能的原因:1.workers实际上没有启动
2.系统中一个进程可以创建多少个线程？（可以通过cat /proc/sys/kernel/threads-max查看）&lt;/p&gt;
&lt;p&gt;可能的方法:1.在import ray后添加 ray.init(num_cpus=56, num_gpus=2)  这个方法很多人似乎有帮助，但不是一个好的解决方案
2.可以看一下/tmp/ray/session_latest/raylet.out,如果在/tmp/ray/session_latest/看到有前缀python-core-worker- 的可以看一下，因为这个能了解工作进程可能发生了什么
3.升级grpcio,2023年的时候安装grpcio 1.48.1 版本是有用的,相应的venv是 CentOS 7,Python 3.7.11，Ray 2.5.1,grpcio1.48.1
4.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;#!/bin/bash
ulimit -n 65536
python3 -m verl.trainer.main_ppo &amp;hellip;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;5.一定要设置参数,只是用ray.init()就会崩溃。需要手动设置num_cpus&lt;/p&gt;
&lt;p&gt;其他人：
2024.1.16也有在Ubuntu 20.04上遇到同样的问题 venv: ray == 2.7.1,grpcio == 1.59.2,python == 3.11.5
2024.4.2有在ubuntu 22.04.3（docker内部）上遇到同样的问题，但是他只是失败，而不是挂起。在docker之外运行良好（他的M1 MacBook上）&lt;/p&gt;
&lt;p&gt;2024.4.14，2024.4.17，2024.7.11等等太多人遇到同样的问题了&lt;/p&gt;
&lt;p&gt;15点左右,/yhy/verl/trainer/config/ppo_trainer.yaml配置文件中进行修改&lt;/p&gt;
&lt;h5 id=&#34;问题已解决在import-ray后添加-rayinitnum_cpus56-num_gpus2&#34;&gt;问题已解决！在import ray后添加 ray.init(num_cpus=56, num_gpus=2)
&lt;/h5&gt;&lt;p&gt;自己看issue，扒仓库源码等等解决了这个问题&lt;/p&gt;
&lt;h4 id=&#34;20251022&#34;&gt;2025.10.22
&lt;/h4&gt;&lt;p&gt;结束了第一段实习，收获满满！&lt;br&gt;
谢谢师兄！谢谢赵老师！&lt;br&gt;
期待后续再合作！&lt;/p&gt;
</description>
        </item>
        <item>
        <title>第一篇文章</title>
        <link>http://localhost:1313/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</link>
        <pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</guid>
        <description>&lt;img src="http://localhost:1313/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/first-blog-cover.jpg" alt="Featured image of post 第一篇文章" /&gt;&lt;p&gt;欢迎你能来到我的第一篇文章！&lt;/p&gt;
&lt;h2 id=&#34;为什么要写博客&#34;&gt;为什么要写博客？
&lt;/h2&gt;&lt;p&gt;写博客对我来说有着特殊的意义：&lt;/p&gt;
&lt;h3 id=&#34;对自己&#34;&gt;对自己
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;记录笔记&lt;/strong&gt;：把学到的东西都记下来，以后可以复习&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;积攒经验&lt;/strong&gt;：积攒宝贵的经验&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;记录进步&lt;/strong&gt;：记录自己的进步&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;对他人&#34;&gt;对他人
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;感谢师父&lt;/strong&gt;：感谢文聪学长的帮助，永远的师傅！&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;传承精神&lt;/strong&gt;：希望后来者能够更快速地入门&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分享内容&lt;/strong&gt;：希望其他人能够更快地了解我&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;博客内容规划&#34;&gt;博客内容规划
&lt;/h2&gt;&lt;p&gt;我计划我的文章中记录以下内容：&lt;/p&gt;
&lt;h3 id=&#34;笔记-notes&#34;&gt;笔记 (Notes)
&lt;/h3&gt;&lt;p&gt;可能比较杂，什么都有。但重点是关于llm的内容&lt;/p&gt;
&lt;h3 id=&#34;理论-theory&#34;&gt;理论 (Theory)
&lt;/h3&gt;&lt;p&gt;一些理论知识&lt;/p&gt;
&lt;h3 id=&#34;日记-diary&#34;&gt;日记 (Diary)
&lt;/h3&gt;&lt;p&gt;记录一些自己的日常，探讨人生&lt;/p&gt;
&lt;h2 id=&#34;结语&#34;&gt;结语
&lt;/h2&gt;&lt;p&gt;写博客是一个长期的过程，也应该是一个很开心的过程！&lt;/p&gt;
&lt;p&gt;&lt;em&gt;这篇文章写于 2025年9月15日，是我博客的第一篇文章。希望它能成为一个美好的开始。&lt;/em&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Archives</title>
        <link>http://localhost:1313/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>About</title>
        <link>http://localhost:1313/about/</link>
        <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/about/</guid>
        <description>&lt;p&gt;Written in Go, Hugo is an open source static site generator available under the &lt;a class=&#34;link&#34; href=&#34;https://github.com/gohugoio/hugo/blob/master/LICENSE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache License 2.0.&lt;/a&gt; Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.&lt;/p&gt;
&lt;p&gt;Hugo makes use of a variety of open source projects including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/yuin/goldmark&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/yuin/goldmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/alecthomas/chroma&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/alecthomas/chroma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/muesli/smartcrop&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/muesli/smartcrop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/spf13/cobra&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/spf13/cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/spf13/viper&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.&lt;/p&gt;
&lt;p&gt;Hugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.&lt;/p&gt;
&lt;p&gt;Websites built with Hugo are extremely fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.&lt;/p&gt;
&lt;p&gt;Learn more and contribute on &lt;a class=&#34;link&#34; href=&#34;https://github.com/gohugoio&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Links</title>
        <link>http://localhost:1313/links/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/links/</guid>
        <description>&lt;p&gt;To use this feature, add &lt;code&gt;links&lt;/code&gt; section to frontmatter.&lt;/p&gt;
&lt;p&gt;This page&amp;rsquo;s frontmatter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;links&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub is the world&amp;#39;s largest software development platform.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://www.typescriptlang.org&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ts-logo-128.jpg&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;image&lt;/code&gt; field accepts both local and external images.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Search</title>
        <link>http://localhost:1313/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/search/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
